"""
å†™å…¥ä¸Šä¸‹æ–‡æ¼”ç¤º (Write Context Demo)
æ¼”ç¤ºå¦‚ä½•åœ¨ LangGraph ä¸­å†™å…¥ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬è‰ç¨¿æœ¬ï¼ˆçŸ­æœŸè®°å¿†ï¼‰å’Œè®°å¿†ï¼ˆé•¿æœŸè®°å¿†ï¼‰
"""

import os
from typing import TypedDict
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.store.base import BaseStore
from rich.console import Console
from rich.panel import Panel

console = Console()

# è®¾ç½®ç¯å¢ƒå˜é‡
def setup_environment():
    """è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡"""
    if not os.environ.get("ANTHROPIC_API_KEY"):
        api_key = input("è¯·è¾“å…¥æ‚¨çš„ ANTHROPIC_API_KEY: ")
        os.environ["ANTHROPIC_API_KEY"] = api_key

# çŠ¶æ€å®šä¹‰
class ResearchState(TypedDict):
    """ç ”ç©¶ä»»åŠ¡çš„çŠ¶æ€å®šä¹‰"""
    topic: str           # ç ”ç©¶ä¸»é¢˜
    initial_thoughts: str # åˆå§‹æƒ³æ³•
    research_plan: str   # ç ”ç©¶è®¡åˆ’
    findings: str        # ç ”ç©¶å‘ç°
    summary: str         # æœ€ç»ˆæ€»ç»“

# åˆå§‹åŒ–ç»„ä»¶
def initialize_components():
    """åˆå§‹åŒ– LLMã€æ£€æŸ¥ç‚¹å’Œå­˜å‚¨"""
    setup_environment()
    
    llm = init_chat_model("anthropic:claude-3-5-sonnet-20241022", temperature=0.7)
    checkpointer = InMemorySaver()  # çŸ­æœŸè®°å¿†ï¼ˆè‰ç¨¿æœ¬ï¼‰
    memory_store = InMemoryStore()  # é•¿æœŸè®°å¿†
    namespace = ("user_demo", "research_assistant")
    
    return llm, checkpointer, memory_store, namespace

# èŠ‚ç‚¹å‡½æ•°
def generate_initial_thoughts(state: ResearchState) -> dict:
    """ç”Ÿæˆåˆå§‹æƒ³æ³•å¹¶å†™å…¥çŠ¶æ€ï¼ˆè‰ç¨¿æœ¬ï¼‰"""
    llm, _, _, _ = initialize_components()
    
    console.print(Panel(
        f"ğŸ§  æ­£åœ¨ä¸ºä¸»é¢˜ '{state['topic']}' ç”Ÿæˆåˆå§‹æƒ³æ³•...",
        title="å†™å…¥ä¸Šä¸‹æ–‡ - è‰ç¨¿æœ¬",
        border_style="blue"
    ))
    
    prompt = f"""ä½œä¸ºä¸€ä¸ªç ”ç©¶åŠ©æ‰‹ï¼Œè¯·ä¸ºä¸»é¢˜ "{state['topic']}" ç”Ÿæˆä¸€äº›åˆå§‹çš„ç ”ç©¶æƒ³æ³•å’Œæ–¹å‘ã€‚
    è¯·æä¾› 3-5 ä¸ªå…·ä½“çš„ç ”ç©¶è§’åº¦æˆ–é—®é¢˜ã€‚"""
    
    response = llm.invoke(prompt)
    thoughts = response.content
    
    console.print(Panel(
        thoughts,
        title="âœ… åˆå§‹æƒ³æ³•å·²å†™å…¥çŠ¶æ€",
        border_style="green"
    ))
    
    # å†™å…¥çŠ¶æ€ï¼ˆè‰ç¨¿æœ¬ï¼‰
    return {"initial_thoughts": thoughts}

def create_research_plan(state: ResearchState, store: BaseStore) -> dict:
    """åŸºäºåˆå§‹æƒ³æ³•åˆ›å»ºç ”ç©¶è®¡åˆ’ï¼Œå¹¶ä¿å­˜åˆ°é•¿æœŸè®°å¿†"""
    llm, _, _, namespace = initialize_components()
    
    console.print(Panel(
        "ğŸ“‹ æ­£åœ¨åˆ›å»ºè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’...",
        title="å†™å…¥ä¸Šä¸‹æ–‡ - é•¿æœŸè®°å¿†",
        border_style="blue"
    ))
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å†å²ç ”ç©¶è®¡åˆ’
    existing_plans = list(store.search(namespace))
    history_context = ""
    if existing_plans:
        history_context = f"\nå†å²ç ”ç©¶è®°å½•ï¼š\n{existing_plans[0].value.get('plan', '')}"
    
    prompt = f"""åŸºäºä»¥ä¸‹åˆå§‹æƒ³æ³•åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’ï¼š

åˆå§‹æƒ³æ³•ï¼š
{state['initial_thoughts']}

{history_context}

è¯·åˆ›å»ºä¸€ä¸ªåŒ…å«ä»¥ä¸‹è¦ç´ çš„ç ”ç©¶è®¡åˆ’ï¼š
1. ç ”ç©¶ç›®æ ‡
2. ç ”ç©¶æ–¹æ³•
3. é¢„æœŸæˆæœ
4. æ—¶é—´å®‰æ’"""
    
    response = llm.invoke(prompt)
    plan = response.content
    
    # ä¿å­˜åˆ°é•¿æœŸè®°å¿†
    store.put(
        namespace,
        f"research_plan_{state['topic'].replace(' ', '_')}",
        {
            "topic": state['topic'],
            "plan": plan,
            "timestamp": "2024-01-01",  # å®é™…åº”ç”¨ä¸­ä½¿ç”¨çœŸå®æ—¶é—´æˆ³
            "type": "research_plan"
        }
    )
    
    console.print(Panel(
        plan,
        title="âœ… ç ”ç©¶è®¡åˆ’å·²ä¿å­˜åˆ°é•¿æœŸè®°å¿†",
        border_style="green"
    ))
    
    return {"research_plan": plan}

def conduct_research(state: ResearchState) -> dict:
    """æ¨¡æ‹Ÿè¿›è¡Œç ”ç©¶å¹¶è®°å½•å‘ç°"""
    llm, _, _, _ = initialize_components()
    
    console.print(Panel(
        "ğŸ” æ­£åœ¨è¿›è¡Œç ”ç©¶å¹¶è®°å½•å‘ç°...",
        title="å†™å…¥ä¸Šä¸‹æ–‡ - è‰ç¨¿æœ¬æ›´æ–°",
        border_style="blue"
    ))
    
    prompt = f"""åŸºäºä»¥ä¸‹ç ”ç©¶è®¡åˆ’è¿›è¡Œæ¨¡æ‹Ÿç ”ç©¶ï¼š

ç ”ç©¶è®¡åˆ’ï¼š
{state['research_plan']}

è¯·æ¨¡æ‹Ÿç ”ç©¶è¿‡ç¨‹å¹¶æä¾›ä¸€äº›å…³é”®å‘ç°å’Œæ´å¯Ÿã€‚"""
    
    response = llm.invoke(prompt)
    findings = response.content
    
    console.print(Panel(
        findings,
        title="âœ… ç ”ç©¶å‘ç°å·²å†™å…¥çŠ¶æ€",
        border_style="green"
    ))
    
    return {"findings": findings}

def create_summary(state: ResearchState, store: BaseStore) -> dict:
    """åˆ›å»ºæœ€ç»ˆæ€»ç»“å¹¶æ›´æ–°é•¿æœŸè®°å¿†"""
    llm, _, _, namespace = initialize_components()
    
    console.print(Panel(
        "ğŸ“ æ­£åœ¨åˆ›å»ºæœ€ç»ˆæ€»ç»“...",
        title="å†™å…¥ä¸Šä¸‹æ–‡ - ç»¼åˆè®°å¿†",
        border_style="blue"
    ))
    
    prompt = f"""åŸºäºæ•´ä¸ªç ”ç©¶è¿‡ç¨‹åˆ›å»ºä¸€ä¸ªç»¼åˆæ€»ç»“ï¼š

ä¸»é¢˜ï¼š{state['topic']}
åˆå§‹æƒ³æ³•ï¼š{state['initial_thoughts']}
ç ”ç©¶è®¡åˆ’ï¼š{state['research_plan']}
ç ”ç©¶å‘ç°ï¼š{state['findings']}

è¯·åˆ›å»ºä¸€ä¸ªåŒ…å«å…³é”®æ´å¯Ÿå’Œç»“è®ºçš„æ€»ç»“ã€‚"""
    
    response = llm.invoke(prompt)
    summary = response.content
    
    # æ›´æ–°é•¿æœŸè®°å¿†ä¸­çš„ç ”ç©¶è®°å½•
    store.put(
        namespace,
        f"research_summary_{state['topic'].replace(' ', '_')}",
        {
            "topic": state['topic'],
            "summary": summary,
            "full_research": {
                "initial_thoughts": state['initial_thoughts'],
                "plan": state['research_plan'],
                "findings": state['findings'],
                "summary": summary
            },
            "timestamp": "2024-01-01",
            "type": "research_summary"
        }
    )
    
    console.print(Panel(
        summary,
        title="âœ… æœ€ç»ˆæ€»ç»“å·²ä¿å­˜åˆ°é•¿æœŸè®°å¿†",
        border_style="green"
    ))
    
    return {"summary": summary}

def build_write_context_workflow():
    """æ„å»ºå†™å…¥ä¸Šä¸‹æ–‡çš„å·¥ä½œæµ"""
    llm, checkpointer, memory_store, namespace = initialize_components()
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(ResearchState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("generate_thoughts", generate_initial_thoughts)
    workflow.add_node("create_plan", create_research_plan)
    workflow.add_node("conduct_research", conduct_research)
    workflow.add_node("create_summary", create_summary)
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "generate_thoughts")
    workflow.add_edge("generate_thoughts", "create_plan")
    workflow.add_edge("create_plan", "conduct_research")
    workflow.add_edge("conduct_research", "create_summary")
    workflow.add_edge("create_summary", END)
    
    # ç¼–è¯‘å·¥ä½œæµï¼ˆåŒ…å«æ£€æŸ¥ç‚¹å’Œå­˜å‚¨ï¼‰
    app = workflow.compile(checkpointer=checkpointer, store=memory_store)
    
    return app, memory_store, namespace

def demonstrate_write_context():
    """æ¼”ç¤ºå†™å…¥ä¸Šä¸‹æ–‡åŠŸèƒ½"""
    console.print(Panel(
        "ğŸš€ LangGraph å†™å…¥ä¸Šä¸‹æ–‡æ¼”ç¤º",
        title="Context Engineering Demo",
        border_style="bold blue"
    ))
    
    app, memory_store, namespace = build_write_context_workflow()
    
    # é…ç½®ä¼šè¯
    config = {"configurable": {"thread_id": "write_demo_1"}}
    
    # è¿è¡Œå·¥ä½œæµ
    topic = "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²ä¸­çš„åº”ç”¨"
    console.print(f"\nğŸ“š å¼€å§‹ç ”ç©¶ä¸»é¢˜: {topic}\n")
    
    result = app.invoke({"topic": topic}, config)
    
    # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    console.print(Panel(
        f"""ä¸»é¢˜: {result['topic']}
        
çŠ¶æ€ä¸­çš„ä¿¡æ¯ï¼ˆè‰ç¨¿æœ¬ï¼‰:
â€¢ åˆå§‹æƒ³æ³•: {len(result['initial_thoughts'])} å­—ç¬¦
â€¢ ç ”ç©¶è®¡åˆ’: {len(result['research_plan'])} å­—ç¬¦  
â€¢ ç ”ç©¶å‘ç°: {len(result['findings'])} å­—ç¬¦
â€¢ æœ€ç»ˆæ€»ç»“: {len(result['summary'])} å­—ç¬¦""",
        title="ğŸ“Š å†™å…¥ä¸Šä¸‹æ–‡æ€»ç»“",
        border_style="bold green"
    ))
    
    # æ˜¾ç¤ºé•¿æœŸè®°å¿†ä¸­çš„å†…å®¹
    stored_items = list(memory_store.search(namespace))
    console.print(Panel(
        f"é•¿æœŸè®°å¿†ä¸­ä¿å­˜äº† {len(stored_items)} é¡¹è®°å½•:\n" + 
        "\n".join([f"â€¢ {item.key}: {item.value['type']}" for item in stored_items]),
        title="ğŸ§  é•¿æœŸè®°å¿†çŠ¶æ€",
        border_style="bold purple"
    ))
    
    return result, memory_store

if __name__ == "__main__":
    result, store = demonstrate_write_context()
