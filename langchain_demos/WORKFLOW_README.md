# ğŸ”„ å·¥ä½œæµä»£ç è§£é‡Šå™¨

è¿™æ˜¯ä¸€ä¸ªæ”¯æŒå¤šå·¥å…·åä½œçš„ä»£ç æ‰§è¡Œç¯å¢ƒï¼Œä¸“é—¨è§£å†³"å…ˆè°ƒç”¨å…¶ä»–å·¥å…·è·å–æ•°æ®ï¼Œå†å°†ç»“æœä¼ é€’ç»™ä»£ç è§£é‡Šå™¨è¿›è¡Œåˆ†æ"çš„åœºæ™¯ã€‚

## ğŸ¯ è§£å†³çš„é—®é¢˜

åœ¨å®é™…ä¸šåŠ¡ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸é‡åˆ°è¿™æ ·çš„éœ€æ±‚ï¼š
1. ä» API è·å–æ•°æ®
2. ä»æ•°æ®åº“æŸ¥è¯¢ä¿¡æ¯  
3. è¯»å–æ–‡ä»¶å†…å®¹
4. **å°†è¿™äº›æ•°æ®ä¼ é€’ç»™ä»£ç è§£é‡Šå™¨è¿›è¡Œå¤æ‚åˆ†æ**
5. æ ¹æ®åˆ†æç»“æœæ‰§è¡Œåç»­æ“ä½œï¼ˆå¦‚å‘é€é‚®ä»¶ã€æ›´æ–°æ•°æ®åº“ç­‰ï¼‰

ä¼ ç»Ÿçš„å•ä¸€å·¥å…·æ— æ³•å¾ˆå¥½åœ°å¤„ç†è¿™ç§å¤šæ­¥éª¤ã€æœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```
WorkflowEngine (å·¥ä½œæµå¼•æ“)
    â”œâ”€â”€ WorkflowContext (ä¸Šä¸‹æ–‡ç®¡ç†)
    â”œâ”€â”€ WorkflowTool (å·¥å…·åŸºç±»)
    â”‚   â”œâ”€â”€ APIDataTool (APIæ•°æ®è·å–)
    â”‚   â”œâ”€â”€ DatabaseTool (æ•°æ®åº“æŸ¥è¯¢)
    â”‚   â”œâ”€â”€ FileDataTool (æ–‡ä»¶è¯»å–)
    â”‚   â”œâ”€â”€ WorkflowCodeInterpreter (ä»£ç è§£é‡Šå™¨)
    â”‚   â””â”€â”€ EmailSenderTool (é‚®ä»¶å‘é€)
    â””â”€â”€ Tool Registration (å·¥å…·æ³¨å†Œæœºåˆ¶)
```

### æ•°æ®æµè½¬

```
Step 1: API/DB/File â†’ WorkflowContext.data
Step 2: WorkflowContext.data â†’ CodeInterpreter  
Step 3: CodeInterpreter â†’ Analysis Results
Step 4: Results â†’ Email/Report/Action
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from workflow_code_interpreter import WorkflowEngine

# åˆ›å»ºå·¥ä½œæµå¼•æ“
engine = WorkflowEngine()

# å®šä¹‰å·¥ä½œæµæ­¥éª¤
workflow_steps = [
    {
        "tool": "api_data_fetcher",
        "description": "è·å–ç”¨æˆ·æ•°æ®",
        "url": "https://jsonplaceholder.typicode.com/users",
        "data_key": "users_data"
    },
    {
        "tool": "workflow_code_interpreter", 
        "description": "åˆ†æç”¨æˆ·æ•°æ®",
        "code": """
# åˆ†æç”¨æˆ·æ•°æ®
users = context_data.get('users_data', [])
print(f'ç”¨æˆ·æ•°é‡: {len(users)}')

# ç»Ÿè®¡åŸå¸‚åˆ†å¸ƒ
cities = [user.get('address', {}).get('city', 'Unknown') for user in users]
city_count = {}
for city in cities:
    city_count[city] = city_count.get(city, 0) + 1

print('åŸå¸‚åˆ†å¸ƒ:')
for city, count in city_count.items():
    print(f'  {city}: {count} äºº')
        """,
        "result_key": "analysis_result"
    }
]

# æ‰§è¡Œå·¥ä½œæµ
result = engine.execute_workflow(workflow_steps)
```

### é«˜çº§ç”¨æ³•ï¼šå¤šæ•°æ®æºåˆ†æ

```python
workflow_steps = [
    # æ­¥éª¤1: è·å–APIæ•°æ®
    {
        "tool": "api_data_fetcher",
        "url": "https://api.example.com/sales",
        "data_key": "sales_data"
    },
    # æ­¥éª¤2: æŸ¥è¯¢æ•°æ®åº“
    {
        "tool": "database_query", 
        "query": "SELECT * FROM customers",
        "data_key": "customer_data"
    },
    # æ­¥éª¤3: è¯»å–é…ç½®æ–‡ä»¶
    {
        "tool": "file_reader",
        "file_path": "/path/to/config.json",
        "data_key": "config_data"
    },
    # æ­¥éª¤4: ç»¼åˆåˆ†æ
    {
        "tool": "workflow_code_interpreter",
        "code": """
# è·å–æ‰€æœ‰æ•°æ®æº
sales = context_data.get('sales_data', [])
customers = context_data.get('customer_data', [])
config = context_data.get('config_data', {})

# æ‰§è¡Œå¤æ‚çš„å…³è”åˆ†æ
print('=== ç»¼åˆä¸šåŠ¡åˆ†æ ===')
# ... ä½ çš„åˆ†æé€»è¾‘
        """,
        "result_key": "comprehensive_analysis"
    },
    # æ­¥éª¤5: å‘é€ç»“æœ
    {
        "tool": "email_sender",
        "to_email": "manager@company.com", 
        "subject": "ä¸šåŠ¡åˆ†ææŠ¥å‘Š",
        "content": "è¯·æŸ¥çœ‹æœ€æ–°çš„ä¸šåŠ¡åˆ†æç»“æœ"
    }
]
```

## ğŸ› ï¸ å†…ç½®å·¥å…·

### 1. APIDataTool - APIæ•°æ®è·å–

```python
{
    "tool": "api_data_fetcher",
    "url": "https://api.example.com/data",
    "method": "GET",  # GET/POST
    "headers": {"Authorization": "Bearer token"},
    "params": {"limit": 100},
    "data_key": "api_data"
}
```

### 2. DatabaseTool - æ•°æ®åº“æŸ¥è¯¢

```python
{
    "tool": "database_query",
    "query": "SELECT * FROM users WHERE active = 1",
    "data_key": "active_users"
}
```

### 3. FileDataTool - æ–‡ä»¶è¯»å–

```python
{
    "tool": "file_reader", 
    "file_path": "/path/to/data.json",
    "file_type": "json",  # json/csv/text/auto
    "data_key": "file_data"
}
```

### 4. WorkflowCodeInterpreter - ä»£ç æ‰§è¡Œ

```python
{
    "tool": "workflow_code_interpreter",
    "code": """
# åœ¨è¿™é‡Œç¼–å†™åˆ†æä»£ç 
# å¯ä»¥é€šè¿‡ context_data è®¿é—®ä¹‹å‰æ­¥éª¤çš„æ•°æ®
data = context_data.get('my_data', [])
# è¿›è¡Œåˆ†æ...
    """,
    "result_key": "analysis_result"
}
```

### 5. EmailSenderTool - é‚®ä»¶å‘é€

```python
{
    "tool": "email_sender",
    "to_email": "user@example.com",
    "subject": "åˆ†ææŠ¥å‘Š", 
    "content": "åˆ†æå·²å®Œæˆï¼Œè¯·æŸ¥çœ‹ç»“æœ"
}
```

## ğŸ”§ è‡ªå®šä¹‰å·¥å…·

### åˆ›å»ºè‡ªå®šä¹‰å·¥å…·

```python
from workflow_code_interpreter import WorkflowTool, WorkflowContext

class CustomDataTool(WorkflowTool):
    def __init__(self):
        super().__init__(
            name="custom_data_fetcher",
            description="è‡ªå®šä¹‰æ•°æ®è·å–å·¥å…·"
        )
    
    def execute(self, context: WorkflowContext, **kwargs) -> dict:
        # å®ç°ä½ çš„é€»è¾‘
        data = self.fetch_custom_data(**kwargs)
        
        # å°†æ•°æ®æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        data_key = kwargs.get('data_key', 'custom_data')
        context.add_data(data_key, data, source="CustomAPI")
        
        return {
            "success": True,
            "data": data,
            "message": "è‡ªå®šä¹‰æ•°æ®è·å–æˆåŠŸ"
        }
    
    def fetch_custom_data(self, **kwargs):
        # ä½ çš„æ•°æ®è·å–é€»è¾‘
        return {"example": "data"}

# æ³¨å†Œè‡ªå®šä¹‰å·¥å…·
engine = WorkflowEngine()
engine.register_tool(CustomDataTool())
```

### æ‰©å±•ä»£ç è§£é‡Šå™¨

```python
class EnhancedCodeInterpreter(WorkflowCodeInterpreter):
    def execute(self, context: WorkflowContext, **kwargs) -> dict:
        # æ·»åŠ é¢å¤–çš„é¢„å¤„ç†é€»è¾‘
        code = kwargs.get('code', '')
        
        # æ³¨å…¥é¢å¤–çš„å·¥å…·å‡½æ•°
        enhanced_code = """
# å·¥å…·å‡½æ•°
def safe_divide(a, b):
    return a / b if b != 0 else 0

def format_currency(amount):
    return f"${amount:,.2f}"

# ç”¨æˆ·ä»£ç :
""" + code
        
        kwargs['code'] = enhanced_code
        return super().execute(context, **kwargs)
```

## ğŸ“Š å®é™…åº”ç”¨ç¤ºä¾‹

### 1. è‚¡ç¥¨åˆ†æå·¥ä½œæµ

```python
# è·å–è‚¡ç¥¨æ•°æ® â†’ æŠ€æœ¯åˆ†æ â†’ ç”ŸæˆæŠ¥å‘Š â†’ å‘é€é‚®ä»¶
workflow_steps = [
    {
        "tool": "stock_data_fetcher",
        "symbol": "AAPL", 
        "days": 30,
        "data_key": "stock_data"
    },
    {
        "tool": "workflow_code_interpreter",
        "code": """
# æŠ€æœ¯åˆ†æä»£ç 
stock_data = context_data.get('stock_data', [])
# è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ã€RSIç­‰æŠ€æœ¯æŒ‡æ ‡
# ç”Ÿæˆä¹°å–ä¿¡å·
        """
    },
    {
        "tool": "email_sender",
        "to_email": "trader@fund.com",
        "subject": "è‚¡ç¥¨åˆ†ææŠ¥å‘Š"
    }
]
```

### 2. ä¸šåŠ¡æ•°æ®ç®¡é“

```python
# è¯»å–åŸå§‹æ•°æ® â†’ æ•°æ®æ¸…æ´— â†’ ç»Ÿè®¡åˆ†æ â†’ ä¿å­˜ç»“æœ
workflow_steps = [
    {
        "tool": "file_reader",
        "file_path": "raw_transactions.csv",
        "data_key": "raw_data"
    },
    {
        "tool": "workflow_code_interpreter", 
        "code": """
# æ•°æ®æ¸…æ´—
raw_data = context_data.get('raw_data', [])
cleaned_data = []
for record in raw_data:
    if self.validate_record(record):
        cleaned_data.append(self.clean_record(record))
        """,
        "result_key": "cleaned_data"
    },
    {
        "tool": "workflow_code_interpreter",
        "code": """
# ç»Ÿè®¡åˆ†æ
cleaned_data = context_data.get('cleaned_data', [])
# ç”Ÿæˆå„ç§ç»Ÿè®¡æŒ‡æ ‡å’Œå›¾è¡¨
        """,
        "result_key": "analysis_report"
    }
]
```

### 3. æ™ºèƒ½ç›‘æ§å‘Šè­¦

```python
# ç›‘æ§æ•°æ®è·å– â†’ å¼‚å¸¸æ£€æµ‹ â†’ å‘Šè­¦å‘é€
workflow_steps = [
    {
        "tool": "api_data_fetcher",
        "url": "https://monitoring.api.com/metrics",
        "data_key": "metrics"
    },
    {
        "tool": "workflow_code_interpreter",
        "code": """
# å¼‚å¸¸æ£€æµ‹ç®—æ³•
metrics = context_data.get('metrics', [])
anomalies = []
for metric in metrics:
    if self.detect_anomaly(metric):
        anomalies.append(metric)
        
if anomalies:
    print(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸")
        """,
        "result_key": "anomaly_detection"
    },
    {
        "tool": "email_sender",
        "to_email": "ops@company.com",
        "subject": "ç³»ç»Ÿå¼‚å¸¸å‘Šè­¦"
    }
]
```

## ğŸ”’ å®‰å…¨æ€§å’Œæ²™ç®±

å·¥ä½œæµä»£ç è§£é‡Šå™¨æ”¯æŒæ²™ç®±æ‰§è¡Œï¼š

```python
from sandboxed_code_interpreter import SandboxConfig

# é…ç½®å®‰å…¨çš„ä»£ç æ‰§è¡Œç¯å¢ƒ
config = SandboxConfig(
    use_docker=True,
    use_restricted_python=True,
    allowed_modules=["math", "json", "statistics"],
    max_execution_time=30
)

# åˆ›å»ºæ²™ç®±åŒ–çš„å·¥ä½œæµè§£é‡Šå™¨
interpreter = WorkflowCodeInterpreter(use_sandbox=True)
```

## ğŸ® äº¤äº’å¼æ¨¡å¼

æ”¯æŒäº¤äº’å¼å·¥ä½œæµæ„å»ºï¼š

```python
python workflow_code_interpreter.py
# é€‰æ‹© "4. äº¤äº’å¼å·¥ä½œæµæ¨¡å¼"

# åœ¨äº¤äº’å¼æ¨¡å¼ä¸­ï¼š
workflow>>> api_data_fetcher url=https://api.example.com data_key=my_data
workflow>>> workflow_code_interpreter code="print(context_data.get('my_data'))"
workflow>>> summary  # æŸ¥çœ‹ä¸Šä¸‹æ–‡æ‘˜è¦
workflow>>> quit
```

## ğŸ”„ ä¸ LangChain é›†æˆ

```python
from workflow_code_interpreter import WorkflowCodeInterpreterTool
from langchain.agents import initialize_agent
from langchain_openai import ChatOpenAI

# åˆ›å»º LangChain å·¥å…·
workflow_tool = WorkflowCodeInterpreterTool()

# é›†æˆåˆ°æ™ºèƒ½ä»£ç†
llm = ChatOpenAI(temperature=0)
agent = initialize_agent(
    tools=[workflow_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

# ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°å·¥ä½œæµ
response = agent.run("""
è¯·æ‰§è¡Œä»¥ä¸‹å·¥ä½œæµ:
1. ä» https://api.example.com/users è·å–ç”¨æˆ·æ•°æ®
2. åˆ†æç”¨æˆ·çš„åœ°ç†åˆ†å¸ƒ
3. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
""")
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
workflow_steps = [
    {
        "tool": "api_data_fetcher",
        "url": "https://api.example.com/data",
        "data_key": "api_data",
        "stop_on_error": True  # å¤±è´¥æ—¶åœæ­¢å·¥ä½œæµ
    },
    # åç»­æ­¥éª¤...
]
```

### 2. æ•°æ®éªŒè¯

```python
{
    "tool": "workflow_code_interpreter",
    "code": """
# æ•°æ®éªŒè¯
data = context_data.get('api_data', [])
if not data:
    raise ValueError("API æ•°æ®ä¸ºç©º")
    
if len(data) < 10:
    print("âš ï¸  æ•°æ®é‡è¾ƒå°‘ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®")
    """
}
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# å¯¹äºå¤§æ•°æ®é‡ï¼Œåˆ†æ‰¹å¤„ç†
{
    "tool": "workflow_code_interpreter", 
    "code": """
data = context_data.get('large_dataset', [])
batch_size = 1000

for i in range(0, len(data), batch_size):
    batch = data[i:i+batch_size]
    # å¤„ç†æ‰¹æ¬¡æ•°æ®
    process_batch(batch)
    """
}
```

### 4. ç»“æœç¼“å­˜

```python
# ç¼“å­˜ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
{
    "tool": "workflow_code_interpreter",
    "code": """
import hashlib
import pickle

# ç”Ÿæˆæ•°æ®å“ˆå¸Œ
data = context_data.get('input_data')
data_hash = hashlib.md5(str(data).encode()).hexdigest()
cache_key = f"analysis_{data_hash}"

# æ£€æŸ¥ç¼“å­˜
if cache_key in context_data:
    result = context_data[cache_key]
    print("ä½¿ç”¨ç¼“å­˜ç»“æœ")
else:
    # æ‰§è¡Œåˆ†æ
    result = expensive_analysis(data)
    context_data[cache_key] = result
    """
}
```

## ğŸ”§ é…ç½®å’Œéƒ¨ç½²

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# API é…ç½®
export API_BASE_URL=https://api.company.com
export API_TOKEN=your_api_token

# æ•°æ®åº“é…ç½®  
export DB_HOST=localhost
export DB_USER=workflow_user
export DB_PASSWORD=secure_password

# é‚®ä»¶é…ç½®
export SMTP_HOST=smtp.company.com
export SMTP_USER=workflow@company.com
export SMTP_PASSWORD=email_password
```

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.11-slim

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY workflow_code_interpreter.py .
COPY workflow_examples.py .

CMD ["python", "workflow_code_interpreter.py"]
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### æ‰§è¡Œç›‘æ§

```python
# è·å–å·¥ä½œæµæ‰§è¡Œç»Ÿè®¡
engine = WorkflowEngine()
result = engine.execute_workflow(steps)

print("æ‰§è¡Œç»Ÿè®¡:")
print(f"æ€»æ­¥éª¤: {len(result['results'])}")
print(f"æˆåŠŸæ­¥éª¤: {sum(1 for r in result['results'] if r.get('success'))}")
print(f"æ‰§è¡Œæ—¶é—´: {total_execution_time}s")
```

### æ—¥å¿—è®°å½•

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åœ¨å·¥å…·ä¸­æ·»åŠ æ—¥å¿—
class CustomTool(WorkflowTool):
    def execute(self, context, **kwargs):
        logger.info(f"æ‰§è¡Œå·¥å…·: {self.name}")
        result = super().execute(context, **kwargs)
        logger.info(f"å·¥å…·æ‰§è¡Œ{'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        return result
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„å·¥å…·å’ŒåŠŸèƒ½ï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. å®ç°æ–°å·¥å…·æˆ–åŠŸèƒ½
4. æ·»åŠ æµ‹è¯•å’Œæ–‡æ¡£
5. æäº¤ Pull Request

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ LICENSE æ–‡ä»¶
