"""
LLM Web Agent é…ç½®æ¨¡å—
"""

import os
from typing import Optional
from dataclasses import dataclass
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


@dataclass
class LLMConfig:
    """LLM é…ç½®"""
    api_key: str
    model_name: str = "gpt-4"
    temperature: float = 0.1
    max_tokens: Optional[int] = None
    base_url: Optional[str] = None
    
    @classmethod
    def from_env(cls) -> "LLMConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        return cls(
            api_key=api_key,
            model_name=os.getenv("OPENAI_MODEL", "gpt-4"),
            temperature=float(os.getenv("OPENAI_TEMPERATURE", "0.1")),
            max_tokens=int(os.getenv("OPENAI_MAX_TOKENS")) if os.getenv("OPENAI_MAX_TOKENS") else None,
            base_url=os.getenv("OPENAI_BASE_URL")
        )


@dataclass
class MCPConfig:
    """MCP æœåŠ¡å™¨é…ç½®"""
    server_url: str = "ws://localhost:8080"
    server_port: int = 8080
    timeout: int = 30
    
    @classmethod
    def from_env(cls) -> "MCPConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            server_url=os.getenv("MCP_SERVER_URL", "ws://localhost:8080"),
            server_port=int(os.getenv("MCP_SERVER_PORT", "8080")),
            timeout=int(os.getenv("MCP_TIMEOUT", "30"))
        )


@dataclass 
class BrowserConfig:
    """æµè§ˆå™¨é…ç½®"""
    headless: bool = False
    timeout: int = 30000
    viewport_width: int = 1280
    viewport_height: int = 720
    user_agent: Optional[str] = None
    
    @classmethod
    def from_env(cls) -> "BrowserConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            headless=os.getenv("BROWSER_HEADLESS", "false").lower() == "true",
            timeout=int(os.getenv("BROWSER_TIMEOUT", "30000")),
            viewport_width=int(os.getenv("BROWSER_WIDTH", "1280")),
            viewport_height=int(os.getenv("BROWSER_HEIGHT", "720")),
            user_agent=os.getenv("BROWSER_USER_AGENT")
        )


@dataclass
class LogConfig:
    """æ—¥å¿—é…ç½®"""
    level: str = "INFO"
    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_path: Optional[str] = None
    
    @classmethod
    def from_env(cls) -> "LogConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            level=os.getenv("LOG_LEVEL", "INFO"),
            format=os.getenv("LOG_FORMAT", "%(asctime)s - %(name)s - %(levelname)s - %(message)s"),
            file_path=os.getenv("LOG_FILE")
        )


@dataclass
class AgentConfig:
    """ä»£ç†é…ç½®"""
    max_iterations: int = 10
    early_stopping_method: str = "generate"
    verbose: bool = True
    memory_type: str = "buffer"
    
    @classmethod
    def from_env(cls) -> "AgentConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            max_iterations=int(os.getenv("AGENT_MAX_ITERATIONS", "10")),
            early_stopping_method=os.getenv("AGENT_EARLY_STOPPING", "generate"),
            verbose=os.getenv("AGENT_VERBOSE", "true").lower() == "true",
            memory_type=os.getenv("AGENT_MEMORY_TYPE", "buffer")
        )


class Config:
    """ä¸»é…ç½®ç±»"""
    
    def __init__(self):
        self.llm = LLMConfig.from_env()
        self.mcp = MCPConfig.from_env()
        self.browser = BrowserConfig.from_env()
        self.log = LogConfig.from_env()
        self.agent = AgentConfig.from_env()
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®"""
        try:
            # éªŒè¯ LLM é…ç½®
            if not self.llm.api_key:
                raise ValueError("OpenAI API Key æœªè®¾ç½®")
            
            # éªŒè¯ç«¯å£èŒƒå›´
            if not (1 <= self.mcp.server_port <= 65535):
                raise ValueError(f"MCP æœåŠ¡å™¨ç«¯å£æ— æ•ˆ: {self.mcp.server_port}")
            
            # éªŒè¯è¶…æ—¶å€¼
            if self.mcp.timeout <= 0:
                raise ValueError(f"MCP è¶…æ—¶å€¼æ— æ•ˆ: {self.mcp.timeout}")
            
            if self.browser.timeout <= 0:
                raise ValueError(f"æµè§ˆå™¨è¶…æ—¶å€¼æ— æ•ˆ: {self.browser.timeout}")
            
            # éªŒè¯è§†å£å¤§å°
            if self.browser.viewport_width <= 0 or self.browser.viewport_height <= 0:
                raise ValueError("æµè§ˆå™¨è§†å£å¤§å°æ— æ•ˆ")
            
            # éªŒè¯æ—¥å¿—çº§åˆ«
            valid_log_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
            if self.log.level.upper() not in valid_log_levels:
                raise ValueError(f"æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {self.log.level}")
            
            # éªŒè¯ä»£ç†é…ç½®
            if self.agent.max_iterations <= 0:
                raise ValueError("ä»£ç†æœ€å¤§è¿­ä»£æ¬¡æ•°å¿…é¡»å¤§äº0")
            
            return True
            
        except ValueError as e:
            print(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def print_config(self):
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        print("ğŸ“‹ å½“å‰é…ç½®:")
        print("-" * 40)
        print(f"LLM æ¨¡å‹: {self.llm.model_name}")
        print(f"LLM æ¸©åº¦: {self.llm.temperature}")
        print(f"MCP æœåŠ¡å™¨: {self.mcp.server_url}")
        print(f"æµè§ˆå™¨æ— å¤´æ¨¡å¼: {self.browser.headless}")
        print(f"æµè§ˆå™¨è§†å£: {self.browser.viewport_width}x{self.browser.viewport_height}")
        print(f"æ—¥å¿—çº§åˆ«: {self.log.level}")
        print(f"ä»£ç†æœ€å¤§è¿­ä»£: {self.agent.max_iterations}")
        print("-" * 40)


# å…¨å±€é…ç½®å®ä¾‹
config = Config()


def load_config() -> Config:
    """åŠ è½½é…ç½®"""
    global config
    config = Config()
    
    if not config.validate():
        raise RuntimeError("é…ç½®éªŒè¯å¤±è´¥")
    
    return config


def get_config() -> Config:
    """è·å–é…ç½®"""
    return config


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    try:
        cfg = load_config()
        cfg.print_config()
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e}")