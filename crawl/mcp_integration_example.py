"""
å®Œæ•´çš„ MCP é›†æˆç¤ºä¾‹ - åœ¨ä½ çš„åº”ç”¨ä¸­ç›´æ¥ä½¿ç”¨ MCP å·¥å…·

è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­é›†æˆ MCP Playwright å·¥å…·
"""

import asyncio
import json
from typing import Dict, Any, Optional, List
from contextlib import AsyncExitStack
from dataclasses import dataclass
from datetime import datetime

# MCP ç›¸å…³å¯¼å…¥
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client


@dataclass
class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    success: bool
    data: Any = None
    error: str = ""
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()


class MCPWebAutomation:
    """åŸºäº MCP çš„ç½‘é¡µè‡ªåŠ¨åŒ–ç³»ç»Ÿ"""
    
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.is_connected = False
        self.available_tools = []
    
    async def initialize(self) -> TaskResult:
        """åˆå§‹åŒ– MCP è¿æ¥"""
        try:
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– MCP è¿æ¥...")
            
            # é…ç½® Playwright MCP æœåŠ¡å™¨
            server_params = StdioServerParameters(
                command="npx",
                args=["@playwright/mcp"],
                env=None
            )
            
            # å»ºç«‹ stdio ä¼ è¾“è¿æ¥
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            )
            stdio, write = stdio_transport
            
            # åˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯
            self.session = await self.exit_stack.enter_async_context(
                ClientSession(stdio, write)
            )
            
            # åˆå§‹åŒ–ä¼šè¯
            await self.session.initialize()
            
            # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
            response = await self.session.list_tools()
            self.available_tools = response.tools
            
            self.is_connected = True
            
            print("âœ… MCP è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
            print(f"ğŸ“‹ å‘ç° {len(self.available_tools)} ä¸ªå¯ç”¨å·¥å…·:")
            for tool in self.available_tools[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  - {tool.name}")
            
            return TaskResult(
                success=True,
                data={
                    "tools_count": len(self.available_tools),
                    "tools": [tool.name for tool in self.available_tools]
                }
            )
            
        except Exception as e:
            error_msg = f"MCP è¿æ¥åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return TaskResult(success=False, error=error_msg)
    
    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> TaskResult:
        """è°ƒç”¨ MCP å·¥å…·çš„é€šç”¨æ–¹æ³•"""
        if not self.is_connected or not self.session:
            return TaskResult(success=False, error="MCP è¿æ¥æœªåˆå§‹åŒ–")
        
        try:
            print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
            result = await self.session.call_tool(tool_name, arguments)
            
            return TaskResult(
                success=True,
                data=result
            )
            
        except Exception as e:
            error_msg = f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return TaskResult(success=False, error=error_msg)
    
    # === å…·ä½“çš„ä¸šåŠ¡æ–¹æ³• ===
    
    async def navigate_to_page(self, url: str) -> TaskResult:
        """å¯¼èˆªåˆ°æŒ‡å®šé¡µé¢"""
        return await self.call_tool("browser_navigate", {"url": url})
    
    async def capture_page_info(self, include_screenshot: bool = True) -> TaskResult:
        """æ•è·é¡µé¢ä¿¡æ¯ï¼ˆå¿«ç…§ + æˆªå›¾ï¼‰"""
        try:
            results = {}
            
            # è·å–é¡µé¢å¿«ç…§
            snapshot_result = await self.call_tool("browser_snapshot", {})
            if snapshot_result.success:
                results["snapshot"] = snapshot_result.data
            
            # æˆªå›¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_screenshot:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                screenshot_result = await self.call_tool(
                    "browser_take_screenshot", 
                    {"filename": f"page_capture_{timestamp}.png"}
                )
                if screenshot_result.success:
                    results["screenshot"] = screenshot_result.data
            
            return TaskResult(success=True, data=results)
            
        except Exception as e:
            return TaskResult(success=False, error=str(e))
    
    async def interact_with_element(self, action: str, element_desc: str, 
                                  element_ref: str, text: str = "") -> TaskResult:
        """ä¸é¡µé¢å…ƒç´ äº¤äº’"""
        try:
            if action == "click":
                return await self.call_tool("browser_click", {
                    "element": element_desc,
                    "ref": element_ref
                })
            elif action == "type":
                return await self.call_tool("browser_type", {
                    "element": element_desc,
                    "ref": element_ref,
                    "text": text,
                    "submit": False
                })
            elif action == "type_and_submit":
                return await self.call_tool("browser_type", {
                    "element": element_desc,
                    "ref": element_ref,
                    "text": text,
                    "submit": True
                })
            else:
                return TaskResult(success=False, error=f"ä¸æ”¯æŒçš„æ“ä½œ: {action}")
                
        except Exception as e:
            return TaskResult(success=False, error=str(e))
    
    async def wait_for_condition(self, condition_type: str, value: Any) -> TaskResult:
        """ç­‰å¾…ç‰¹å®šæ¡ä»¶"""
        try:
            args = {}
            if condition_type == "time":
                args["time"] = value
            elif condition_type == "text":
                args["text"] = value
            
            return await self.call_tool("browser_wait_for", args)
            
        except Exception as e:
            return TaskResult(success=False, error=str(e))
    
    # === é«˜çº§ä¸šåŠ¡æµç¨‹ ===
    
    async def scrape_website_data(self, url: str, wait_time: float = 2) -> TaskResult:
        """å®Œæ•´çš„ç½‘ç«™æ•°æ®æŠ“å–æµç¨‹"""
        try:
            print(f"\nğŸ•·ï¸ å¼€å§‹æŠ“å–ç½‘ç«™: {url}")
            
            # 1. å¯¼èˆªåˆ°é¡µé¢
            nav_result = await self.navigate_to_page(url)
            if not nav_result.success:
                return nav_result
            
            # 2. ç­‰å¾…é¡µé¢åŠ è½½
            await self.wait_for_condition("time", wait_time)
            
            # 3. æ•è·é¡µé¢ä¿¡æ¯
            page_info = await self.capture_page_info(include_screenshot=True)
            if not page_info.success:
                return page_info
            
            # 4. æ•´ç†ç»“æœ
            scraped_data = {
                "url": url,
                "navigation_result": nav_result.data,
                "page_snapshot": page_info.data.get("snapshot"),
                "screenshot_info": page_info.data.get("screenshot"),
                "scrape_timestamp": datetime.now().isoformat()
            }
            
            print("âœ… ç½‘ç«™æŠ“å–å®Œæˆ")
            return TaskResult(success=True, data=scraped_data)
            
        except Exception as e:
            return TaskResult(success=False, error=f"ç½‘ç«™æŠ“å–å¤±è´¥: {str(e)}")
    
    async def automated_form_filling(self, form_url: str, 
                                   form_fields: Dict[str, str]) -> TaskResult:
        """è‡ªåŠ¨åŒ–è¡¨å•å¡«å†™æµç¨‹"""
        try:
            print(f"\nğŸ“ å¼€å§‹è‡ªåŠ¨åŒ–è¡¨å•å¡«å†™: {form_url}")
            
            # 1. å¯¼èˆªåˆ°è¡¨å•é¡µé¢
            nav_result = await self.navigate_to_page(form_url)
            if not nav_result.success:
                return nav_result
            
            # 2. ç­‰å¾…é¡µé¢åŠ è½½
            await self.wait_for_condition("time", 2)
            
            # 3. è·å–é¡µé¢å¿«ç…§æ¥åˆ†æè¡¨å•ç»“æ„
            snapshot_result = await self.capture_page_info(include_screenshot=False)
            if not snapshot_result.success:
                return snapshot_result
            
            # 4. è§£æå¿«ç…§ï¼Œæ‰¾åˆ°è¡¨å•å…ƒç´ ï¼ˆè¿™é‡Œéœ€è¦å…·ä½“çš„è§£æé€»è¾‘ï¼‰
            snapshot_data = snapshot_result.data.get("snapshot")
            
            # æ³¨æ„ï¼šå®é™…é¡¹ç›®ä¸­ï¼Œä½ éœ€è¦è§£æ snapshot_data æ¥æ‰¾åˆ°è¡¨å•å…ƒç´ çš„å¼•ç”¨
            # è¿™é‡Œåªæ˜¯æ¼”ç¤ºç»“æ„
            
            form_results = {
                "form_url": form_url,
                "form_fields": form_fields,
                "snapshot_obtained": True,
                "page_analyzed": True,
                "note": "éœ€è¦å®ç°å¿«ç…§è§£æé€»è¾‘æ¥è‡ªåŠ¨æ‰¾åˆ°è¡¨å•å…ƒç´ "
            }
            
            print("âš ï¸ è¡¨å•åˆ†æå®Œæˆï¼Œéœ€è¦å®ç°å…ƒç´ è§£æé€»è¾‘")
            return TaskResult(success=True, data=form_results)
            
        except Exception as e:
            return TaskResult(success=False, error=f"è¡¨å•å¡«å†™å¤±è´¥: {str(e)}")
    
    async def monitor_page_changes(self, url: str, check_interval: int = 30, 
                                 max_checks: int = 5) -> TaskResult:
        """ç›‘æ§é¡µé¢å˜åŒ–"""
        try:
            print(f"\nğŸ“Š å¼€å§‹ç›‘æ§é¡µé¢å˜åŒ–: {url}")
            
            changes_log = []
            
            for i in range(max_checks):
                print(f"ğŸ” ç¬¬ {i+1}/{max_checks} æ¬¡æ£€æŸ¥...")
                
                # å¯¼èˆªåˆ°é¡µé¢
                await self.navigate_to_page(url)
                await self.wait_for_condition("time", 2)
                
                # æ•è·å½“å‰çŠ¶æ€
                page_info = await self.capture_page_info(include_screenshot=True)
                
                check_record = {
                    "check_number": i + 1,
                    "timestamp": datetime.now().isoformat(),
                    "success": page_info.success,
                    "data": page_info.data if page_info.success else None,
                    "error": page_info.error if not page_info.success else None
                }
                
                changes_log.append(check_record)
                
                if i < max_checks - 1:
                    print(f"â³ ç­‰å¾… {check_interval} ç§’...")
                    await self.wait_for_condition("time", check_interval)
            
            print("âœ… é¡µé¢ç›‘æ§å®Œæˆ")
            return TaskResult(success=True, data={
                "url": url,
                "total_checks": max_checks,
                "changes_log": changes_log
            })
            
        except Exception as e:
            return TaskResult(success=False, error=f"é¡µé¢ç›‘æ§å¤±è´¥: {str(e)}")
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.exit_stack:
            await self.exit_stack.aclose()
            self.is_connected = False
            print("âœ… MCP è¿æ¥å·²å…³é—­")


# === ä½¿ç”¨ç¤ºä¾‹ ===

class WebScrapingService:
    """åŸºäº MCP çš„ç½‘é¡µæŠ“å–æœåŠ¡"""
    
    def __init__(self):
        self.automation = MCPWebAutomation()
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æœåŠ¡"""
        result = await self.automation.initialize()
        return result.success
    
    async def scrape_multiple_sites(self, urls: List[str]) -> List[TaskResult]:
        """æ‰¹é‡æŠ“å–å¤šä¸ªç½‘ç«™"""
        results = []
        
        for url in urls:
            print(f"\n{'='*60}")
            print(f"æŠ“å–ç½‘ç«™: {url}")
            print('='*60)
            
            result = await self.automation.scrape_website_data(url)
            results.append(result)
            
            # æ¯ä¸ªç½‘ç«™ä¹‹é—´ç­‰å¾…ä¸€ä¸‹
            await self.automation.wait_for_condition("time", 1)
        
        return results
    
    async def scrape_with_form_interaction(self, form_url: str, 
                                         form_data: Dict[str, str]) -> TaskResult:
        """æŠ“å–éœ€è¦è¡¨å•äº¤äº’çš„ç½‘ç«™"""
        return await self.automation.automated_form_filling(form_url, form_data)
    
    async def monitor_website(self, url: str, interval: int = 60, 
                            checks: int = 10) -> TaskResult:
        """ç›‘æ§ç½‘ç«™å˜åŒ–"""
        return await self.automation.monitor_page_changes(url, interval, checks)
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.automation.cleanup()


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨"""
    print("ğŸš€ MCP é›†æˆç¤ºä¾‹ - åœ¨ä½ çš„ä»£ç ä¸­ç›´æ¥ä½¿ç”¨ MCP å·¥å…·")
    print("=" * 70)
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    scraping_service = WebScrapingService()
    
    try:
        # åˆå§‹åŒ–æœåŠ¡
        if not await scraping_service.initialize():
            print("âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
            return
        
        # ç¤ºä¾‹1: æ‰¹é‡æŠ“å–ç½‘ç«™
        print("\n" + "="*50 + " ç¤ºä¾‹1: æ‰¹é‡ç½‘ç«™æŠ“å– " + "="*50)
        urls_to_scrape = [
            "https://httpbin.org/html",
            "https://httpbin.org/json",
            "https://httpbin.org/user-agent"
        ]
        
        scrape_results = await scraping_service.scrape_multiple_sites(urls_to_scrape)
        
        print(f"\nğŸ“Š æŠ“å–ç»“æœæ±‡æ€»:")
        for i, result in enumerate(scrape_results):
            status = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±è´¥"
            print(f"  {i+1}. {urls_to_scrape[i]}: {status}")
        
        # ç¤ºä¾‹2: è¡¨å•äº¤äº’æŠ“å–
        print("\n" + "="*50 + " ç¤ºä¾‹2: è¡¨å•äº¤äº’ " + "="*50)
        form_result = await scraping_service.scrape_with_form_interaction(
            "https://httpbin.org/forms/post",
            {"name": "æµ‹è¯•ç”¨æˆ·", "email": "test@example.com"}
        )
        
        print(f"è¡¨å•äº¤äº’ç»“æœ: {'âœ… æˆåŠŸ' if form_result.success else 'âŒ å¤±è´¥'}")
        
        # ç¤ºä¾‹3: ç½‘ç«™ç›‘æ§ï¼ˆçŸ­æ—¶é—´æ¼”ç¤ºï¼‰
        print("\n" + "="*50 + " ç¤ºä¾‹3: ç½‘ç«™ç›‘æ§ " + "="*50)
        monitor_result = await scraping_service.monitor_website(
            "https://httpbin.org/uuid",  # æ¯æ¬¡è®¿é—®è¿”å›ä¸åŒUUID
            interval=5,  # 5ç§’é—´éš”
            checks=3     # åªæ£€æŸ¥3æ¬¡
        )
        
        print(f"ç½‘ç«™ç›‘æ§ç»“æœ: {'âœ… æˆåŠŸ' if monitor_result.success else 'âŒ å¤±è´¥'}")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    finally:
        # æ¸…ç†èµ„æº
        await scraping_service.cleanup()


if __name__ == "__main__":
    print("ğŸ“‹ ä½¿ç”¨å‰è¯·ç¡®ä¿å·²å®‰è£…:")
    print("  1. npm install -g @playwright/mcp")
    print("  2. pip install mcp")
    print("  3. playwright install")
    print()
    
    asyncio.run(main())