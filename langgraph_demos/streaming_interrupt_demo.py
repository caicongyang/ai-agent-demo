"""
LangGraph æµå¼äººæœºäº¤äº’æ¼”ç¤º - æ”¯æŒå®æ—¶æ‰“æ–­å’Œä¸Šä¸‹æ–‡æ›´æ–°

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•åœ¨ LLM è¾“å‡ºè¿‡ç¨‹ä¸­å®ç°ï¼š
1. æµå¼è¾“å‡º
2. ç”¨æˆ·å®æ—¶æ‰“æ–­
3. ä¸Šä¸‹æ–‡åŠ¨æ€æ›´æ–°
4. æ— ç¼æ¢å¤æ‰§è¡Œ

åŸºäº LangGraph å®˜æ–¹çš„ interrupt() å’Œ Command(resume=...) API
"""

import os
import asyncio
import threading
import time
from typing import Annotated, Dict, Any, List, Optional
from typing_extensions import TypedDict
from queue import Queue, Empty

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class StreamingInterruptState(TypedDict):
    """
    æµå¼äººæœºäº¤äº’çŠ¶æ€å®šä¹‰
    
    åŒ…å«äº†æ•´ä¸ªæµå¼äº¤äº’è¿‡ç¨‹ä¸­éœ€è¦çš„æ‰€æœ‰çŠ¶æ€ï¼š
    - user_input: ç”¨æˆ·è¾“å…¥
    - ai_response: AIçš„å›å¤
    - conversation_history: å¯¹è¯å†å²
    - interrupt_requested: æ˜¯å¦è¯·æ±‚äº†ä¸­æ–­
    - user_interrupt: ç”¨æˆ·ä¸­æ–­çš„æ¶ˆæ¯
    - streaming_content: æµå¼è¾“å‡ºçš„å†…å®¹
    - context_updated: ä¸Šä¸‹æ–‡æ˜¯å¦å·²æ›´æ–°
    """
    user_input: str
    ai_response: str
    conversation_history: List[Dict[str, str]]
    interrupt_requested: bool
    user_interrupt: str
    streaming_content: str
    context_updated: bool


class StreamingInterruptDemo:
    """
    æµå¼äººæœºäº¤äº’æ¼”ç¤ºç±»
    
    å®ç°äº†ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æµå¼è¾“å‡ºLLMå“åº”
    2. åœ¨è¾“å‡ºè¿‡ç¨‹ä¸­æ£€æµ‹ç”¨æˆ·æ‰“æ–­
    3. æ ¹æ®ç”¨æˆ·è¾“å…¥æ›´æ–°ä¸Šä¸‹æ–‡
    4. æ— ç¼æ¢å¤æˆ–é‡æ–°å¼€å§‹å¯¹è¯
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºå®ä¾‹"""
        logger.info("åˆå§‹åŒ– StreamingInterruptDemo...")
        
        # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=os.getenv("LLM_API_KEY"),
            base_url=os.getenv("LLM_BASE_URL"),
            streaming=True  # å¯ç”¨æµå¼è¾“å‡º
        )
        
        # åˆ›å»ºå¯¹è¯æç¤ºæ¨¡æ¿
        self.chat_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ­£åœ¨ä¸ç”¨æˆ·è¿›è¡Œå¯¹è¯ã€‚
ä½ çš„å›å¤ä¼šä»¥æµå¼æ–¹å¼è¾“å‡ºï¼Œç”¨æˆ·å¯èƒ½åœ¨ä½ å›å¤è¿‡ç¨‹ä¸­æ‰“æ–­ä½ ã€‚
å¦‚æœç”¨æˆ·æ‰“æ–­äº†ä½ ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æ–°è¾“å…¥è°ƒæ•´ä½ çš„å›å¤ã€‚

å¯¹è¯å†å²ï¼š
{conversation_history}

å½“å‰ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¯·æä¾›æœ‰ç”¨ã€è¯¦ç»†çš„å›å¤ã€‚å¦‚æœç”¨æˆ·æåˆ°äº†æ–°çš„è¯é¢˜æˆ–é—®é¢˜ï¼Œè¯·ç›¸åº”åœ°è°ƒæ•´ä½ çš„å›å¤å†…å®¹ã€‚"""),
        ])
        
        # åˆ›å»ºæ›´æ–°ä¸Šä¸‹æ–‡çš„æç¤ºæ¨¡æ¿
        self.context_update_prompt = ChatPromptTemplate.from_messages([
            ("system", """ç”¨æˆ·åœ¨ä½ å›å¤è¿‡ç¨‹ä¸­æ‰“æ–­äº†ä½ ï¼Œå¹¶æä¾›äº†æ–°çš„ä¿¡æ¯æˆ–é—®é¢˜ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„æ‰“æ–­ä¿¡æ¯ï¼Œé‡æ–°ç»„ç»‡ä½ çš„å›å¤ã€‚

åŸå§‹ç”¨æˆ·è¾“å…¥ï¼š{original_input}
å¯¹è¯å†å²ï¼š{conversation_history}
ä½ æ­£åœ¨è¾“å‡ºçš„å†…å®¹ï¼š{streaming_content}
ç”¨æˆ·æ‰“æ–­çš„æ¶ˆæ¯ï¼š{user_interrupt}

è¯·æä¾›ä¸€ä¸ªæ–°çš„ã€æ›´åˆé€‚çš„å›å¤ï¼Œè€ƒè™‘ç”¨æˆ·çš„æ‰“æ–­å’Œæ–°çš„ä¸Šä¸‹æ–‡ã€‚"""),
        ])
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨
        self.checkpointer = MemorySaver()
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        self.workflow = self._create_workflow()
        
        # ç”¨æˆ·è¾“å…¥é˜Ÿåˆ—ï¼ˆç”¨äºå¼‚æ­¥æ¥æ”¶ç”¨æˆ·æ‰“æ–­ï¼‰
        self.user_input_queue = Queue()
        self.interrupt_event = threading.Event()
        
        logger.info("æµå¼ä¸­æ–­å·¥ä½œæµåˆ›å»ºå®Œæˆ")
    
    async def streaming_response_node(self, state: StreamingInterruptState) -> Dict:
        """
        æµå¼å“åº”èŠ‚ç‚¹
        
        ç”Ÿæˆæµå¼AIå›å¤ï¼ŒåŒæ—¶ç›‘å¬ç”¨æˆ·æ‰“æ–­
        """
        try:
            logger.info("å¼€å§‹æµå¼å“åº”...")
            
            # æ„å»ºå¯¹è¯å†å²å­—ç¬¦ä¸²
            history_str = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in state.get("conversation_history", [])
            ])
            
            # åˆ›å»ºå“åº”é“¾
            response_chain = self.chat_prompt | self.llm
            
            # å¼€å§‹æµå¼ç”Ÿæˆ
            streaming_content = ""
            interrupt_detected = False
            user_interrupt_message = ""
            
            print(f"\nğŸ¤– AIæ­£åœ¨å›å¤: ", end="", flush=True)
            print(f"\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥ç›´æ¥è¾“å…¥æ–°æ¶ˆæ¯å¹¶æŒ‰å›è½¦æ¥æ‰“æ–­AIå›å¤")
            
            # é‡ç½®ä¸­æ–­äº‹ä»¶å’Œé˜Ÿåˆ—
            self.interrupt_event.clear()
            while not self.user_input_queue.empty():
                try:
                    self.user_input_queue.get_nowait()
                except Empty:
                    break
            
            # å¯åŠ¨ç”¨æˆ·è¾“å…¥ç›‘å¬çº¿ç¨‹
            input_thread = threading.Thread(target=self._listen_for_user_input, daemon=True)
            input_thread.start()
            
            # æµå¼ç”Ÿæˆå“åº”
            async for chunk in response_chain.astream({
                "conversation_history": history_str,
                "user_input": state["user_input"]
            }):
                if hasattr(chunk, 'content') and chunk.content:
                    content = chunk.content
                    streaming_content += content
                    print(content, end="", flush=True)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·æ‰“æ–­
                    if self.interrupt_event.is_set():
                        try:
                            user_interrupt_message = self.user_input_queue.get_nowait()
                            interrupt_detected = True
                            # ä¸åœ¨è¿™é‡Œæ‰“å°ï¼Œå› ä¸ºç›‘å¬çº¿ç¨‹å·²ç»æ‰“å°äº†
                            break
                        except Empty:
                            pass
                    
                    # æ·»åŠ å°å»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®çš„æµå¼è¾“å‡ºï¼ŒåŒæ—¶ç»™ä¸­æ–­æ£€æµ‹æ›´å¤šæœºä¼š
                    await asyncio.sleep(0.1)
            
            print()  # æ¢è¡Œ
            
            if interrupt_detected:
                # ç”¨æˆ·æ‰“æ–­äº†ï¼Œéœ€è¦å¤„ç†ä¸­æ–­
                print("ğŸ”„ æ£€æµ‹åˆ°ç”¨æˆ·æ‰“æ–­ï¼Œæ­£åœ¨å¤„ç†...")
                
                # ç›´æ¥è¿”å›ä¸­æ–­çŠ¶æ€ï¼Œä¸ä½¿ç”¨ interrupt() å‡½æ•°
                # å› ä¸ºæˆ‘ä»¬è¦åœ¨åº”ç”¨å±‚å¤„ç†ä¸­æ–­ï¼Œè€Œä¸æ˜¯åœ¨å›¾æ‰§è¡Œå±‚
                return {
                    "ai_response": streaming_content,
                    "streaming_content": streaming_content,
                    "interrupt_requested": True,
                    "user_interrupt": user_interrupt_message,
                    "context_updated": False,
                    "interrupt_data": {
                        "type": "user_interrupt",
                        "original_input": state["user_input"],
                        "streaming_content": streaming_content,
                        "user_interrupt": user_interrupt_message,
                        "conversation_history": state.get("conversation_history", [])
                    }
                }
            else:
                # æ­£å¸¸å®Œæˆå›å¤
                return {
                    "ai_response": streaming_content,
                    "streaming_content": streaming_content,
                    "interrupt_requested": False,
                    "user_interrupt": "",
                    "context_updated": False
                }
                
        except Exception as e:
            logger.error(f"æµå¼å“åº”èŠ‚ç‚¹å‡ºé”™: {str(e)}")
            return {
                "ai_response": f"æŠ±æ­‰ï¼Œç”Ÿæˆå›å¤æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "streaming_content": "",
                "interrupt_requested": False,
                "user_interrupt": "",
                "context_updated": False
            }
    
    async def context_update_node(self, state: StreamingInterruptState) -> Dict:
        """
        ä¸Šä¸‹æ–‡æ›´æ–°èŠ‚ç‚¹
        
        æ ¹æ®ç”¨æˆ·æ‰“æ–­ä¿¡æ¯æ›´æ–°ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆæ–°çš„å›å¤
        """
        try:
            logger.info("æ›´æ–°ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆæ–°å›å¤...")
            
            # æ„å»ºå¯¹è¯å†å²å­—ç¬¦ä¸²
            history_str = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in state.get("conversation_history", [])
            ])
            
            # åˆ›å»ºä¸Šä¸‹æ–‡æ›´æ–°é“¾
            update_chain = self.context_update_prompt | self.llm
            
            # ç”Ÿæˆæ–°çš„å›å¤
            result = await update_chain.ainvoke({
                "original_input": state["user_input"],
                "conversation_history": history_str,
                "streaming_content": state.get("streaming_content", ""),
                "user_interrupt": state.get("user_interrupt", "")
            })
            
            new_response = result.content if hasattr(result, 'content') else str(result)
            
            print(f"\nğŸ”„ åŸºäºç”¨æˆ·æ‰“æ–­ç”Ÿæˆçš„æ–°å›å¤:")
            print(f"ğŸ’¬ {new_response}")
            
            return {
                "ai_response": new_response,
                "context_updated": True,
                "interrupt_requested": False
            }
            
        except Exception as e:
            logger.error(f"ä¸Šä¸‹æ–‡æ›´æ–°èŠ‚ç‚¹å‡ºé”™: {str(e)}")
            return {
                "ai_response": f"æ›´æ–°ä¸Šä¸‹æ–‡æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "context_updated": True,
                "interrupt_requested": False
            }
    
    def conversation_update_node(self, state: StreamingInterruptState) -> Dict:
        """
        å¯¹è¯æ›´æ–°èŠ‚ç‚¹
        
        æ›´æ–°å¯¹è¯å†å²
        """
        conversation_history = state.get("conversation_history", []).copy()
        
        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²
        conversation_history.append({
            "role": "user", 
            "content": state["user_input"]
        })
        
        # æ·»åŠ AIå›å¤åˆ°å†å²
        conversation_history.append({
            "role": "assistant", 
            "content": state["ai_response"]
        })
        
        # å¦‚æœæœ‰ç”¨æˆ·æ‰“æ–­ï¼Œä¹Ÿæ·»åŠ åˆ°å†å²
        if state.get("user_interrupt"):
            conversation_history.append({
                "role": "user", 
                "content": f"[æ‰“æ–­] {state['user_interrupt']}"
            })
        
        return {
            "conversation_history": conversation_history
        }
    
    def decide_next_step(self, state: StreamingInterruptState) -> str:
        """
        å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
        
        åŸºäºå½“å‰çŠ¶æ€å†³å®šæ˜¯å¦éœ€è¦æ›´æ–°ä¸Šä¸‹æ–‡
        """
        if state.get("interrupt_requested", False) and not state.get("context_updated", False):
            return "context_update"
        else:
            return "conversation_update"
    
    def _listen_for_user_input(self):
        """
        ç›‘å¬ç”¨æˆ·è¾“å…¥çš„åå°çº¿ç¨‹å‡½æ•°
        æŒç»­ç›‘å¬ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒå®æ—¶æ‰“æ–­
        """
        import select
        import sys
        import tty
        import termios
        
        try:
            # ä¿å­˜åŸå§‹ç»ˆç«¯è®¾ç½®
            if sys.stdin.isatty():
                old_settings = termios.tcgetattr(sys.stdin.fileno())
                tty.setraw(sys.stdin.fileno())
            
            input_buffer = ""
            
            while not self.interrupt_event.is_set():
                try:
                    # ä½¿ç”¨selectæ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥å¯ç”¨
                    if hasattr(select, 'select'):
                        ready, _, _ = select.select([sys.stdin], [], [], 0.1)
                        if ready:
                            # è¯»å–å•ä¸ªå­—ç¬¦
                            char = sys.stdin.read(1)
                            
                            if char == '\r' or char == '\n':  # å›è½¦é”®
                                if input_buffer.strip():
                                    self.user_input_queue.put(input_buffer.strip())
                                    self.interrupt_event.set()
                                    print(f"\n\nâš ï¸  æ£€æµ‹åˆ°ç”¨æˆ·æ‰“æ–­: {input_buffer.strip()}")
                                    break
                                input_buffer = ""
                            elif char == '\x7f' or char == '\b':  # é€€æ ¼é”®
                                if input_buffer:
                                    input_buffer = input_buffer[:-1]
                                    # æ¸…é™¤å­—ç¬¦æ˜¾ç¤º
                                    print('\b \b', end='', flush=True)
                            elif char.isprintable():  # å¯æ‰“å°å­—ç¬¦
                                input_buffer += char
                                print(char, end='', flush=True)
                            elif char == '\x03':  # Ctrl+C
                                break
                    else:
                        # å¦‚æœä¸æ”¯æŒselectï¼Œä½¿ç”¨ç®€å•çš„é˜»å¡input
                        time.sleep(0.1)
                        
                except (KeyboardInterrupt, EOFError):
                    break
                except Exception as e:
                    logger.debug(f"è¾“å…¥ç›‘å¬å¼‚å¸¸: {e}")
                    break
                    
        except Exception as e:
            logger.error(f"è®¾ç½®ç»ˆç«¯æ¨¡å¼å¤±è´¥: {e}")
        finally:
            # æ¢å¤åŸå§‹ç»ˆç«¯è®¾ç½®
            try:
                if sys.stdin.isatty() and 'old_settings' in locals():
                    termios.tcsetattr(sys.stdin.fileno(), termios.TCSADRAIN, old_settings)
            except:
                pass
    
    def _create_workflow(self) -> StateGraph:
        """
        åˆ›å»ºæµå¼ä¸­æ–­å·¥ä½œæµå›¾
        """
        workflow = StateGraph(StreamingInterruptState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("streaming_response", self.streaming_response_node)
        workflow.add_node("context_update", self.context_update_node)
        workflow.add_node("conversation_update", self.conversation_update_node)
        
        # æ·»åŠ è¾¹
        workflow.add_edge(START, "streaming_response")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "streaming_response",
            self.decide_next_step,
            {
                "context_update": "context_update",
                "conversation_update": "conversation_update"
            }
        )
        
        workflow.add_edge("context_update", "conversation_update")
        workflow.add_edge("conversation_update", END)
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    async def run_conversation(self, user_input: str, thread_id: str = "default") -> Dict[str, Any]:
        """
        è¿è¡Œå¯¹è¯
        
        æ”¯æŒæµå¼è¾“å‡ºå’Œç”¨æˆ·æ‰“æ–­
        """
        # é‡ç½®ä¸­æ–­çŠ¶æ€
        self.interrupt_event.clear()
        while not self.user_input_queue.empty():
            try:
                self.user_input_queue.get_nowait()
            except Empty:
                break
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        config = {"configurable": {"thread_id": thread_id}}
        
        # è·å–å½“å‰å¯¹è¯å†å²
        try:
            current_state = self.workflow.get_state(config)
            conversation_history = current_state.values.get("conversation_history", []) if current_state.values else []
        except:
            conversation_history = []
        
        inputs = StreamingInterruptState(
            user_input=user_input,
            ai_response="",
            conversation_history=conversation_history,
            interrupt_requested=False,
            user_interrupt="",
            streaming_content="",
            context_updated=False
        )
        
        result_steps = []
        
        try:
            # è¿è¡Œå·¥ä½œæµ
            async for event in self.workflow.astream(inputs, config):
                for k, v in event.items():
                    if k != "__end__":
                        result_steps.append({k: v})
                        
                        # æ£€æŸ¥æ˜¯å¦é‡åˆ°äº†interrupt
                        if k == "streaming_response" and v.get("interrupt_requested"):
                            print("\nğŸ”„ å·¥ä½œæµæ£€æµ‹åˆ°ç”¨æˆ·æ‰“æ–­ï¼Œå‡†å¤‡å¤„ç†...")
                            interrupt_data = v.get("interrupt_data", {})
                            return {
                                "status": "interrupted",
                                "thread_id": thread_id,
                                "interrupt_data": {
                                    "original_input": interrupt_data.get("original_input", user_input),
                                    "streaming_content": interrupt_data.get("streaming_content", v.get("streaming_content", "")),
                                    "user_interrupt": interrupt_data.get("user_interrupt", v.get("user_interrupt", ""))
                                },
                                "steps": result_steps
                            }
            
            return {
                "status": "completed",
                "thread_id": thread_id,
                "steps": result_steps
            }
            
        except Exception as e:
            logger.error(f"è¿è¡Œå¯¹è¯æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "thread_id": thread_id,
                "steps": result_steps
            }
    
    async def resume_conversation(self, thread_id: str, user_interrupt: str) -> Dict[str, Any]:
        """
        æ¢å¤è¢«ä¸­æ–­çš„å¯¹è¯
        
        æ ¹æ®ç”¨æˆ·æ‰“æ–­ä¿¡æ¯æ›´æ–°ä¸Šä¸‹æ–‡å¹¶ç»§ç»­
        """
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            # ä½¿ç”¨Commandæ¢å¤æ‰§è¡Œ
            result_steps = []
            async for event in self.workflow.astream(
                Command(resume={
                    "type": "user_interrupt_processed",
                    "user_interrupt": user_interrupt
                }), 
                config
            ):
                for k, v in event.items():
                    if k != "__end__":
                        result_steps.append({k: v})
            
            return {
                "status": "resumed",
                "thread_id": thread_id,
                "steps": result_steps
            }
            
        except Exception as e:
            logger.error(f"æ¢å¤å¯¹è¯æ—¶å‡ºé”™: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "thread_id": thread_id
            }


async def interactive_streaming_demo():
    """
    äº¤äº’å¼æµå¼æ¼”ç¤º
    
    å±•ç¤ºå®æ—¶æ‰“æ–­åŠŸèƒ½
    """
    print("ğŸ¯ æµå¼äººæœºäº¤äº’æ¼”ç¤º - æ”¯æŒå®æ—¶æ‰“æ–­")
    print("ğŸ’¡ æç¤º: åœ¨AIå›å¤è¿‡ç¨‹ä¸­ï¼Œæ‚¨å¯ä»¥è¾“å…¥æ–°çš„æ¶ˆæ¯æ¥æ‰“æ–­AI")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print("="*60)
    
    demo = StreamingInterruptDemo()
    thread_id = "interactive_demo"
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if not user_input:
                continue
            
            print(f"\nğŸ”„ å¤„ç†ä¸­...")
            print(f"ğŸ’¡ é‡è¦æç¤º: å½“AIå¼€å§‹å›å¤æ—¶ï¼Œæ‚¨å¯ä»¥ç›´æ¥è¾“å…¥æ–°æ¶ˆæ¯å¹¶æŒ‰å›è½¦æ¥å®æ—¶æ‰“æ–­!")
            
            # è¿è¡Œå¯¹è¯
            result = await demo.run_conversation(user_input, thread_id)
            
            if result["status"] == "interrupted":
                print(f"\nâš ï¸  å¯¹è¯è¢«ä¸­æ–­!")
                print(f"ğŸ“ åŸå§‹è¾“å…¥: {user_input}")
                print(f"ğŸ”„ å·²è¾“å‡ºå†…å®¹: {result['interrupt_data']['streaming_content']}")
                print(f"ğŸ’¬ ç”¨æˆ·æ‰“æ–­: {result['interrupt_data']['user_interrupt']}")
                
                # æ¢å¤å¯¹è¯
                print("\nğŸ”„ æ­£åœ¨æ ¹æ®æ‚¨çš„æ‰“æ–­æ›´æ–°å›å¤...")
                resume_result = await demo.resume_conversation(
                    thread_id, 
                    result['interrupt_data']['user_interrupt']
                )
                
                if resume_result["status"] == "resumed":
                    print("âœ… å¯¹è¯å·²æ¢å¤å¹¶æ›´æ–°!")
                else:
                    print(f"âŒ æ¢å¤å¯¹è¯å¤±è´¥: {resume_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            elif result["status"] == "completed":
                print("\nâœ… å¯¹è¯å®Œæˆ!")
            
            else:
                print(f"\nâŒ å¯¹è¯å‡ºé”™: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            logger.error(f"äº¤äº’æ¼”ç¤ºå‡ºé”™: {str(e)}")
            print(f"âŒ é”™è¯¯: {e}")


async def simple_demo():
    """
    ç®€å•æ¼”ç¤º
    
    å±•ç¤ºåŸºæœ¬çš„æµå¼è¾“å‡ºåŠŸèƒ½
    """
    print("ğŸš€ ç®€å•æµå¼æ¼”ç¤º")
    print("="*50)
    
    demo = StreamingInterruptDemo()
    
    test_inputs = [
        "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿå®ƒæœ‰å“ªäº›åº”ç”¨ï¼Ÿ",
        "è¯·è¯¦ç»†è§£é‡Šæ·±åº¦å­¦ä¹ çš„å·¥ä½œåŸç†"
    ]
    
    for i, user_input in enumerate(test_inputs, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {user_input}")
        print("-" * 50)
        
        try:
            result = await demo.run_conversation(user_input, f"demo_thread_{i}")
            
            if result["status"] == "completed":
                print(f"\nâœ… æµ‹è¯• {i} å®Œæˆ!")
            else:
                print(f"\nâŒ æµ‹è¯• {i} å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            logger.error(f"ç®€å•æ¼”ç¤ºå‡ºé”™: {str(e)}")
            print(f"âŒ æµ‹è¯• {i} å‡ºé”™: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. ç®€å•æ¼”ç¤º (å±•ç¤ºåŸºæœ¬æµå¼è¾“å‡º)")
    print("2. äº¤äº’å¼æ¼”ç¤º (æ”¯æŒå®æ—¶æ‰“æ–­)")
    
    choice = input("è¯·é€‰æ‹© (1/2): ").strip()
    
    if choice == "1":
        await simple_demo()
    elif choice == "2":
        await interactive_streaming_demo()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œç®€å•æ¼”ç¤º...")
        await simple_demo()


if __name__ == "__main__":
    asyncio.run(main())
