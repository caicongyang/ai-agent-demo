# LangGraph Context æ·±å…¥æŒ‡å—

## ç›®å½•
- [æ¦‚è¿°](#æ¦‚è¿°)
- [Contextå·¥ç¨‹æ ¸å¿ƒç†å¿µ](#contextå·¥ç¨‹æ ¸å¿ƒç†å¿µ)
- [Contextçš„ä¸¤ä¸ªç»´åº¦](#contextçš„ä¸¤ä¸ªç»´åº¦)
- [ä¸‰ç§Contextç±»å‹è¯¦è§£](#ä¸‰ç§contextç±»å‹è¯¦è§£)
- [é¡¹ç›®å®æˆ˜æ¡ˆä¾‹åˆ†æ](#é¡¹ç›®å®æˆ˜æ¡ˆä¾‹åˆ†æ)
- [Contextæœ€ä½³å®è·µ](#contextæœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)

## æ¦‚è¿°

**Contextå·¥ç¨‹**æ˜¯æ„å»ºåŠ¨æ€ç³»ç»Ÿçš„å®è·µï¼Œå®ƒä»¥æ­£ç¡®çš„æ ¼å¼æä¾›æ­£ç¡®çš„ä¿¡æ¯å’Œå·¥å…·ï¼Œä½¿AIåº”ç”¨èƒ½å¤Ÿå®Œæˆä»»åŠ¡ã€‚åœ¨LangGraphä¸­ï¼ŒContextæ˜¯æ™ºèƒ½ä½“è·å–å’Œä½¿ç”¨å„ç§ä¿¡æ¯çš„æ ¸å¿ƒæœºåˆ¶ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦Contextï¼Ÿ

æƒ³è±¡ä¸€ä¸ªæ²¡æœ‰Contextçš„æ™ºèƒ½ä½“ï¼š
```python
# âŒ æ²¡æœ‰Contextçš„æ™ºèƒ½ä½“
def simple_agent(user_input):
    return llm.invoke(user_input)  # åªæœ‰ç”¨æˆ·è¾“å…¥ï¼Œç¼ºä¹èƒŒæ™¯ä¿¡æ¯
```

æœ‰äº†Contextçš„æ™ºèƒ½ä½“ï¼š
```python
# âœ… æœ‰Contextçš„æ™ºèƒ½ä½“
def context_aware_agent(user_input, context):
    system_prompt = f"ç”¨æˆ·å: {context.user_name}, åå¥½: {context.preferences}"
    return llm.invoke([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ])
```

Contextè®©æ™ºèƒ½ä½“èƒ½å¤Ÿï¼š
- ğŸ¯ **ä¸ªæ€§åŒ–å“åº”**: æ ¹æ®ç”¨æˆ·ä¿¡æ¯è°ƒæ•´å›ç­”é£æ ¼
- ğŸ”§ **è®¿é—®å·¥å…·**: ä½¿ç”¨æ•°æ®åº“è¿æ¥ã€APIå¯†é’¥ç­‰èµ„æº
- ğŸ’¾ **ä¿æŒçŠ¶æ€**: åœ¨å¯¹è¯è¿‡ç¨‹ä¸­è®°ä½ä¸­é—´ç»“æœ
- ğŸŒ **è·¨ä¼šè¯è®°å¿†**: åœ¨ä¸åŒå¯¹è¯é—´å…±äº«ä¿¡æ¯

## Contextå·¥ç¨‹æ ¸å¿ƒç†å¿µ

æ ¹æ®[LangGraphå®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/agents/context/)ï¼ŒContextå·¥ç¨‹çš„æ ¸å¿ƒæ˜¯**åœ¨æ­£ç¡®çš„æ—¶é—´ï¼Œä»¥æ­£ç¡®çš„æ ¼å¼ï¼Œæä¾›æ­£ç¡®çš„ä¿¡æ¯**ã€‚

### Context vs LLM Context

âš ï¸ **é‡è¦åŒºåˆ«**ï¼š
- **Runtime Context**: ä»£ç è¿è¡Œæ—¶éœ€è¦çš„æœ¬åœ°æ•°æ®å’Œä¾èµ–
- **LLM Context**: ä¼ é€’ç»™LLMæç¤ºè¯çš„æ•°æ®
- **Context Window**: LLMèƒ½å¤„ç†çš„æœ€å¤§tokenæ•°é‡

```python
# Runtime Context - è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
context = Context(
    user_id="alice-123",
    database_url="postgresql://...",
    api_keys={"openai": "sk-..."}
)

# LLM Context - LLMä¸Šä¸‹æ–‡ (ç”±Runtime Contextä¼˜åŒ–ç”Ÿæˆ)
llm_messages = [
    {"role": "system", "content": f"ç”¨æˆ·ID: {context.user_id}"},
    {"role": "user", "content": "Hello"}
]
```

## Contextçš„ä¸¤ä¸ªç»´åº¦

LangGraphé€šè¿‡ä¸¤ä¸ªå…³é”®ç»´åº¦æ¥åˆ†ç±»Contextï¼š

### 1. å¯å˜æ€§ (Mutability)

```
é™æ€Context (Static)              åŠ¨æ€Context (Dynamic)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä¸å¯å˜æ•°æ®         â”‚          â”‚    å¯å˜æ•°æ®         â”‚
â”‚   â€¢ ç”¨æˆ·å…ƒæ•°æ®       â”‚          â”‚   â€¢ å¯¹è¯å†å²        â”‚
â”‚   â€¢ æ•°æ®åº“è¿æ¥       â”‚          â”‚   â€¢ ä¸­é—´ç»“æœ        â”‚
â”‚   â€¢ å·¥å…·é…ç½®         â”‚          â”‚   â€¢ å·¥å…·è°ƒç”¨è§‚å¯Ÿ    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ç”Ÿå‘½å‘¨æœŸ (Lifetime)

```
è¿è¡Œæ—¶Context (Runtime)          è·¨ä¼šè¯Context (Cross-conversation)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å•æ¬¡è¿è¡ŒèŒƒå›´       â”‚          â”‚   å¤šæ¬¡ä¼šè¯èŒƒå›´       â”‚
â”‚   â€¢ å½“å‰å¯¹è¯çŠ¶æ€     â”‚          â”‚   â€¢ ç”¨æˆ·æ¡£æ¡ˆ        â”‚
â”‚   â€¢ ä¸´æ—¶å˜é‡         â”‚          â”‚   â€¢ å†å²åå¥½        â”‚
â”‚   â€¢ å·¥å…·è°ƒç”¨ç»“æœ     â”‚          â”‚   â€¢ å­¦ä¹ ç»éªŒ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ä¸‰ç§Contextç±»å‹è¯¦è§£

æ ¹æ®å¯å˜æ€§å’Œç”Ÿå‘½å‘¨æœŸçš„ç»„åˆï¼ŒLangGraphæä¾›ä¸‰ç§Contextç®¡ç†æ–¹å¼ï¼š

| Contextç±»å‹ | æè¿° | å¯å˜æ€§ | ç”Ÿå‘½å‘¨æœŸ | è®¿é—®æ–¹å¼ |
|------------|------|--------|----------|----------|
| **é™æ€è¿è¡Œæ—¶Context** | å¯åŠ¨æ—¶ä¼ å…¥çš„ç”¨æˆ·å…ƒæ•°æ®ã€å·¥å…·ã€æ•°æ®åº“è¿æ¥ | é™æ€ | å•æ¬¡è¿è¡Œ | `context`å‚æ•° |
| **åŠ¨æ€è¿è¡Œæ—¶Context (çŠ¶æ€)** | å•æ¬¡è¿è¡Œä¸­æ¼”åŒ–çš„å¯å˜æ•°æ® | åŠ¨æ€ | å•æ¬¡è¿è¡Œ | LangGraphçŠ¶æ€å¯¹è±¡ |
| **åŠ¨æ€è·¨ä¼šè¯Context (å­˜å‚¨)** | è·¨ä¼šè¯æŒä¹…åŒ–çš„å…±äº«æ•°æ® | åŠ¨æ€ | è·¨ä¼šè¯ | LangGraphå­˜å‚¨ |

### 1. é™æ€è¿è¡Œæ—¶Context

é™æ€è¿è¡Œæ—¶Contextä»£è¡¨ä¸å¯å˜æ•°æ®ï¼Œåœ¨è¿è¡Œå¼€å§‹æ—¶é€šè¿‡`context`å‚æ•°ä¼ å…¥ã€‚

#### åŸºæœ¬ç”¨æ³•

```python
from dataclasses import dataclass
from langgraph.runtime import get_runtime

@dataclass
class ContextSchema:
    user_name: str
    user_id: str
    model: str
    api_keys: dict

# åœ¨å›¾è°ƒç”¨æ—¶ä¼ å…¥
result = await graph.ainvoke(
    {"messages": [{"role": "user", "content": "Hello"}]},
    context={
        "user_name": "Alice",
        "user_id": "alice-123", 
        "model": "gpt-4",
        "api_keys": {"openai": "sk-..."}
    }
)
```

#### åœ¨ä¸åŒç»„ä»¶ä¸­è®¿é—®

**åœ¨Agentä¸­ä½¿ç”¨**ï¼š
```python
from langchain_core.messages import AnyMessage
from langgraph.runtime import get_runtime
from langgraph.prebuilt import create_react_agent

def prompt(state) -> list[AnyMessage]:
    runtime = get_runtime(ContextSchema)
    user_name = runtime.context.user_name
    
    system_msg = f"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·ç§°å‘¼ç”¨æˆ·ä¸º{user_name}ã€‚"
    return [{"role": "system", "content": system_msg}] + state["messages"]

agent = create_react_agent(
    model="anthropic:claude-3-5-sonnet-latest",
    tools=[get_weather],
    prompt=prompt,
    context_schema=ContextSchema
)
```

**åœ¨å·¥ä½œæµèŠ‚ç‚¹ä¸­ä½¿ç”¨**ï¼š
```python
from langgraph.runtime import Runtime

def my_node(state: State, runtime: Runtime[ContextSchema]):
    user_id = runtime.context.user_id
    model = runtime.context.model
    
    # ä½¿ç”¨contextä¿¡æ¯å¤„ç†é€»è¾‘
    result = process_with_user_context(state, user_id, model)
    return {"processed_result": result}
```

**åœ¨å·¥å…·ä¸­ä½¿ç”¨**ï¼š
```python
from langgraph.runtime import get_runtime
from langchain_core.tools import tool

@tool
def get_user_profile() -> str:
    """è·å–ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯"""
    runtime = get_runtime(ContextSchema)
    user_id = runtime.context.user_id
    
    # ä»æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
    profile = database.get_user_profile(user_id)
    return f"ç”¨æˆ·æ¡£æ¡ˆ: {profile}"
```

### 2. åŠ¨æ€è¿è¡Œæ—¶Context (çŠ¶æ€)

åŠ¨æ€è¿è¡Œæ—¶Contexté€šè¿‡LangGraphçŠ¶æ€å¯¹è±¡ç®¡ç†ï¼Œä»£è¡¨åœ¨å•æ¬¡è¿è¡Œä¸­å¯ä»¥æ¼”åŒ–çš„å¯å˜æ•°æ®ã€‚

#### çŠ¶æ€å®šä¹‰

```python
from typing_extensions import TypedDict
from langchain_core.messages import AnyMessage
from langgraph.graph import add_messages

class CustomState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]
    user_name: str           # ç”¨æˆ·å
    conversation_summary: str # å¯¹è¯æ‘˜è¦
    tool_results: list       # å·¥å…·è°ƒç”¨ç»“æœ
    processing_step: int     # å¤„ç†æ­¥éª¤è®¡æ•°
```

#### åœ¨Agentä¸­ä½¿ç”¨çŠ¶æ€

```python
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

class CustomAgentState(AgentState):
    user_preferences: dict
    conversation_context: str

def prompt(state: CustomAgentState) -> list[AnyMessage]:
    user_prefs = state.get("user_preferences", {})
    context = state.get("conversation_context", "")
    
    system_msg = f"""
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚
    ç”¨æˆ·åå¥½: {user_prefs}
    å¯¹è¯ä¸Šä¸‹æ–‡: {context}
    """
    return [{"role": "system", "content": system_msg}] + state["messages"]

agent = create_react_agent(
    model="anthropic:claude-3-5-sonnet-latest",
    tools=[...],
    state_schema=CustomAgentState,
    prompt=prompt
)
```

#### åœ¨å·¥ä½œæµä¸­ç®¡ç†çŠ¶æ€

```python
from langgraph.graph import StateGraph

def process_input(state: CustomState):
    """å¤„ç†ç”¨æˆ·è¾“å…¥"""
    messages = state["messages"]
    last_message = messages[-1].content
    
    # æ›´æ–°å¤„ç†æ­¥éª¤
    step = state.get("processing_step", 0) + 1
    
    return {
        "processing_step": step,
        "conversation_summary": f"å¤„ç†æ­¥éª¤{step}: {last_message[:50]}..."
    }

def call_tools(state: CustomState):
    """è°ƒç”¨å·¥å…·"""
    # æ ¹æ®çŠ¶æ€ä¿¡æ¯å†³å®šè°ƒç”¨å“ªäº›å·¥å…·
    if state["processing_step"] > 3:
        return {"tool_results": ["å·¥å…·Aç»“æœ", "å·¥å…·Bç»“æœ"]}
    return {}

# æ„å»ºå›¾
builder = StateGraph(CustomState)
builder.add_node("process_input", process_input)
builder.add_node("call_tools", call_tools)
builder.add_edge("process_input", "call_tools")
```

### 3. åŠ¨æ€è·¨ä¼šè¯Context (å­˜å‚¨)

åŠ¨æ€è·¨ä¼šè¯Contexté€šè¿‡LangGraph Storeç®¡ç†ï¼Œä»£è¡¨è·¨å¤šä¸ªä¼šè¯æŒä¹…åŒ–çš„å…±äº«æ•°æ®ã€‚

#### åŸºæœ¬å­˜å‚¨æ“ä½œ

```python
from langgraph.store.memory import InMemoryStore

# åˆ›å»ºå­˜å‚¨
store = InMemoryStore()

# å­˜å‚¨ç”¨æˆ·åå¥½
await store.aput(
    namespace=("user_preferences", "alice-123"),
    key="communication_style",
    value={
        "language": "ä¸­æ–‡",
        "tone": "å‹å¥½",
        "detail_level": "ç®€æ´"
    }
)

# æ£€ç´¢ç”¨æˆ·åå¥½
preferences = await store.aget(
    namespace=("user_preferences", "alice-123"),
    key="communication_style"
)
```

#### åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨å­˜å‚¨

```python
from langgraph.runtime import Runtime
from langgraph.store.base import BaseStore

async def personalized_response(state: State, runtime: Runtime[ContextSchema]):
    user_id = runtime.context.user_id
    store = runtime.store
    
    # æ£€ç´¢ç”¨æˆ·å†å²åå¥½
    preferences = await store.asearch(
        namespace=("preferences", user_id),
        query="é€šä¿¡é£æ ¼"
    )
    
    # æ£€ç´¢ç›¸å…³è®°å¿†
    memories = await store.asearch(
        namespace=("memories", user_id),
        query=str(state["messages"][-1].content)
    )
    
    # åŸºäºåå¥½å’Œè®°å¿†ç”Ÿæˆå“åº”
    context_info = {
        "preferences": [p.value for p in preferences],
        "memories": [m.value for m in memories]
    }
    
    return {"context_info": context_info}
```

## é¡¹ç›®å®æˆ˜æ¡ˆä¾‹åˆ†æ

è®©æˆ‘ä»¬åˆ†æå½“å‰memory-agenté¡¹ç›®ä¸­Contextçš„å®é™…ä½¿ç”¨ï¼š

### é¡¹ç›®ä¸­çš„Contextå®šä¹‰

```python
# src/memory_agent/context.py
@dataclass(kw_only=True)
class Context:
    user_id: str = "default"
    model: str = "anthropic/claude-3-5-sonnet-20240620"
    system_prompt: str = SYSTEM_PROMPT
    
    def __post_init__(self):
        # è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
        for f in fields(self):
            if getattr(self, f.name) == f.default:
                env_value = os.environ.get(f.name.upper(), f.default)
                setattr(self, f.name, env_value)
```

è¿™æ˜¯ä¸€ä¸ª**é™æ€è¿è¡Œæ—¶Context**çš„å…¸å‹å®ç°ï¼ŒåŒ…å«ï¼š
- `user_id`: ç”¨æˆ·æ ‡è¯†ç¬¦
- `model`: æ¨¡å‹é…ç½®
- `system_prompt`: ç³»ç»Ÿæç¤ºè¯

### Contextåœ¨å›¾ä¸­çš„ä½¿ç”¨

```python
# src/memory_agent/graph.py
async def call_model(state: State, runtime: Runtime[Context]) -> dict:
    # 1. ä»Contextè·å–é…ç½®
    user_id = runtime.context.user_id
    model = runtime.context.model
    system_prompt = runtime.context.system_prompt
    
    # 2. ä»Storeè·å–è·¨ä¼šè¯æ•°æ®
    memories = await cast(BaseStore, runtime.store).asearch(
        ("memories", user_id),  # ä½¿ç”¨user_idæ„å»ºå‘½åç©ºé—´
        query=str([m.content for m in state.messages[-3:]]),
        limit=10,
    )
    
    # 3. ç»“åˆContextå’ŒStoreæ•°æ®
    formatted_memories = "\n".join(
        f"[{mem.key}]: {mem.value} (similarity: {mem.score})" 
        for mem in memories
    )
    
    # 4. æ„å»ºæœ€ç»ˆçš„LLMä¸Šä¸‹æ–‡
    sys = system_prompt.format(
        user_info=formatted_memories, 
        time=datetime.now().isoformat()
    )
    
    # 5. è°ƒç”¨æ¨¡å‹
    current_llm = get_model(model)
    msg = await current_llm.bind_tools([tools.upsert_memory]).ainvoke(
        [{"role": "system", "content": sys}, *state.messages],
    )
    return {"messages": [msg]}
```

### Contextçš„ä¸‰å±‚æ¶æ„

åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼ŒContextå½¢æˆäº†ä¸‰å±‚æ¶æ„ï¼š

```mermaid
graph TB
    subgraph "é™æ€è¿è¡Œæ—¶Context"
        SC[Contextå¯¹è±¡]
        SC --> UI[user_id]
        SC --> MODEL[model]
        SC --> PROMPT[system_prompt]
    end
    
    subgraph "åŠ¨æ€è¿è¡Œæ—¶Context (çŠ¶æ€)"
        STATE[Stateå¯¹è±¡]
        STATE --> MSGS[messages]
        STATE --> TEMP[ä¸´æ—¶æ•°æ®]
    end
    
    subgraph "åŠ¨æ€è·¨ä¼šè¯Context (å­˜å‚¨)"
        STORE[Storeå­˜å‚¨]
        STORE --> NS1["å‘½åç©ºé—´: (memories, user_id)"]
        STORE --> NS2["å‘½åç©ºé—´: (preferences, user_id)"]
        NS1 --> M1[è®°å¿†1]
        NS1 --> M2[è®°å¿†2]
        NS2 --> P1[åå¥½1]
        NS2 --> P2[åå¥½2]
    end
    
    SC -.-> STATE
    SC -.-> STORE
    STATE -.-> STORE
    
    style SC fill:#e3f2fd
    style STATE fill:#f3e5f5
    style STORE fill:#e8f5e8
```

### å®é™…è°ƒç”¨ç¤ºä¾‹

```python
# tests/integration_tests/test_graph.py
async def test_memory_storage():
    # 1. åˆ›å»ºå­˜å‚¨ (è·¨ä¼šè¯Context)
    mem_store = InMemoryStore()
    
    # 2. ç¼–è¯‘å›¾ (çŠ¶æ€Context)
    graph = builder.compile(store=mem_store, checkpointer=MemorySaver())
    
    # 3. è°ƒç”¨æ—¶ä¼ å…¥é™æ€Context
    result = await graph.ainvoke(
        {"messages": [("user", "æˆ‘å«Aliceï¼Œå–œæ¬¢æŠ«è¨")]},  # åŠ¨æ€çŠ¶æ€
        {"thread_id": "test-thread"},                    # çŠ¶æ€æ ‡è¯†
        context=Context(                                # é™æ€Context
            user_id="test-user",
            model="azure_openai/gpt-4o"
        ),
    )
```

## Contextæœ€ä½³å®è·µ

### 1. Contextè®¾è®¡åŸåˆ™

```python
# âœ… å¥½çš„Contextè®¾è®¡
@dataclass
class WellDesignedContext:
    # æ ¸å¿ƒæ ‡è¯†
    user_id: str
    session_id: str
    
    # é…ç½®ä¿¡æ¯
    model: str = "gpt-4"
    language: str = "zh-CN"
    
    # èµ„æºè¿æ¥
    database_url: Optional[str] = None
    api_keys: dict = field(default_factory=dict)
    
    # åŠŸèƒ½å¼€å…³
    enable_memory: bool = True
    enable_tools: bool = True

# âŒ é¿å…çš„Contextè®¾è®¡
@dataclass
class PoorContext:
    data: dict  # è¿‡äºå®½æ³›
    config: str  # ç±»å‹ä¸æ˜ç¡®
    everything: Any  # æ²¡æœ‰ç»“æ„
```

### 2. Contextè®¿é—®æ¨¡å¼

```python
# âœ… å®‰å…¨çš„Contextè®¿é—®
def safe_context_access(runtime: Runtime[Context]):
    try:
        user_id = runtime.context.user_id
        model = getattr(runtime.context, 'model', 'default-model')
        return user_id, model
    except AttributeError as e:
        logger.error(f"Contextè®¿é—®é”™è¯¯: {e}")
        return "default-user", "default-model"

# âœ… ContextéªŒè¯
def validate_context(context: Context) -> bool:
    required_fields = ['user_id', 'model']
    for field in required_fields:
        if not getattr(context, field, None):
            raise ValueError(f"Contextç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
    return True
```

### 3. Contextä¸Storeçš„åä½œ

```python
async def context_store_integration(
    state: State, 
    runtime: Runtime[Context]
) -> dict:
    user_id = runtime.context.user_id
    store = runtime.store
    
    # 1. ä½¿ç”¨Contextä¿¡æ¯æ„å»ºå‘½åç©ºé—´
    user_namespace = ("users", user_id)
    session_namespace = ("sessions", runtime.context.session_id)
    
    # 2. åŸºäºContextæ£€ç´¢ç›¸å…³æ•°æ®
    user_data = await store.asearch(user_namespace)
    session_data = await store.asearch(session_namespace)
    
    # 3. ç»“åˆContextå’ŒStoreæ•°æ®åšå†³ç­–
    if runtime.context.enable_memory and user_data:
        # ä½¿ç”¨è®°å¿†å¢å¼ºå“åº”
        enhanced_prompt = build_memory_enhanced_prompt(
            base_prompt=runtime.context.system_prompt,
            memories=user_data
        )
    else:
        enhanced_prompt = runtime.context.system_prompt
    
    return {"enhanced_prompt": enhanced_prompt}
```

### 4. Contextçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
class ContextManager:
    def __init__(self):
        self.active_contexts = {}
    
    async def create_context(self, user_id: str, **kwargs) -> Context:
        """åˆ›å»ºæ–°çš„Context"""
        context = Context(user_id=user_id, **kwargs)
        
        # éªŒè¯Context
        self.validate_context(context)
        
        # åˆå§‹åŒ–ç›¸å…³èµ„æº
        await self.initialize_resources(context)
        
        # ç¼“å­˜Context
        self.active_contexts[user_id] = context
        return context
    
    async def cleanup_context(self, user_id: str):
        """æ¸…ç†Contextèµ„æº"""
        if user_id in self.active_contexts:
            context = self.active_contexts[user_id]
            await self.cleanup_resources(context)
            del self.active_contexts[user_id]
    
    async def initialize_resources(self, context: Context):
        """åˆå§‹åŒ–Contextç›¸å…³èµ„æº"""
        if context.database_url:
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            pass
        
        if context.api_keys:
            # éªŒè¯APIå¯†é’¥
            pass
    
    async def cleanup_resources(self, context: Context):
        """æ¸…ç†Contextç›¸å…³èµ„æº"""
        # å…³é—­æ•°æ®åº“è¿æ¥ã€æ¸…ç†ç¼“å­˜ç­‰
        pass
```

### 5. Contextçš„æµ‹è¯•ç­–ç•¥

```python
# æµ‹è¯•é™æ€Context
@pytest.fixture
def test_context():
    return Context(
        user_id="test-user",
        model="test-model",
        system_prompt="æµ‹è¯•æç¤ºè¯"
    )

async def test_context_usage(test_context):
    # æ¨¡æ‹Ÿå›¾è°ƒç”¨
    result = await graph.ainvoke(
        {"messages": [("user", "test")]},
        context=test_context
    )
    
    # éªŒè¯Contextæ˜¯å¦æ­£ç¡®ä½¿ç”¨
    assert "test-user" in str(result)

# æµ‹è¯•Contextå’ŒStoreçš„é›†æˆ
async def test_context_store_integration():
    store = InMemoryStore()
    context = Context(user_id="integration-test")
    
    # é¢„è®¾æ•°æ®
    await store.aput(
        ("users", "integration-test"),
        "profile",
        {"name": "Test User"}
    )
    
    # æµ‹è¯•é›†æˆ
    result = await graph.ainvoke(
        {"messages": [("user", "Hello")]},
        context=context,
        store=store
    )
    
    assert result is not None
```

## å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: Contextæ•°æ®è¿‡å¤§å¯¼è‡´æ€§èƒ½é—®é¢˜

**é—®é¢˜**: ContextåŒ…å«å¤§é‡æ•°æ®ï¼Œå½±å“ä¼ é€’å’Œè®¿é—®æ€§èƒ½ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… å»¶è¿ŸåŠ è½½Context
@dataclass
class LazyContext:
    user_id: str
    _user_profile: Optional[dict] = None
    _database_connection: Optional[Any] = None
    
    async def get_user_profile(self) -> dict:
        if self._user_profile is None:
            self._user_profile = await load_user_profile(self.user_id)
        return self._user_profile
    
    async def get_database(self):
        if self._database_connection is None:
            self._database_connection = await create_db_connection()
        return self._database_connection

# âœ… Contextåˆ†å±‚
@dataclass
class CoreContext:
    user_id: str
    session_id: str

@dataclass
class ExtendedContext(CoreContext):
    preferences: dict = field(default_factory=dict)
    tools_config: dict = field(default_factory=dict)
```

### Q2: Contextåœ¨ä¸åŒç»„ä»¶é—´ä¸ä¸€è‡´

**é—®é¢˜**: åœ¨Agentã€å·¥å…·ã€èŠ‚ç‚¹ä¸­è®¿é—®åˆ°çš„Contextä¸ä¸€è‡´ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… Contextå•ä¾‹æ¨¡å¼
class ContextSingleton:
    _instance = None
    _context = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def set_context(self, context: Context):
        self._context = context
    
    def get_context(self) -> Context:
        if self._context is None:
            raise RuntimeError("Contextæœªåˆå§‹åŒ–")
        return self._context

# âœ… ContextéªŒè¯ä¸­é—´ä»¶
async def context_validation_middleware(
    state: State, 
    runtime: Runtime[Context]
) -> dict:
    # éªŒè¯Contextå®Œæ•´æ€§
    required_fields = ['user_id', 'model']
    for field in required_fields:
        if not getattr(runtime.context, field, None):
            raise ValueError(f"Contextç¼ºå°‘å­—æ®µ: {field}")
    
    # éªŒè¯Contextå’ŒStoreçš„ä¸€è‡´æ€§
    user_id = runtime.context.user_id
    store_user_data = await runtime.store.asearch(("users", user_id))
    
    if store_user_data and store_user_data[0].value.get("user_id") != user_id:
        raise ValueError("Contextå’ŒStoreä¸­çš„user_idä¸ä¸€è‡´")
    
    return state
```

### Q3: Contextå®‰å…¨æ€§é—®é¢˜

**é—®é¢˜**: Contextä¸­åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œå­˜åœ¨æ³„éœ²é£é™©ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… æ•æ„Ÿä¿¡æ¯åŠ å¯†
from cryptography.fernet import Fernet

@dataclass
class SecureContext:
    user_id: str
    _encrypted_api_keys: bytes
    _cipher: Fernet = field(init=False)
    
    def __post_init__(self):
        # åˆå§‹åŒ–åŠ å¯†å™¨
        key = os.environ.get("CONTEXT_ENCRYPTION_KEY").encode()
        self._cipher = Fernet(key)
    
    def get_api_key(self, service: str) -> str:
        # è§£å¯†APIå¯†é’¥
        decrypted_keys = json.loads(
            self._cipher.decrypt(self._encrypted_api_keys).decode()
        )
        return decrypted_keys.get(service)
    
    def set_api_keys(self, keys: dict):
        # åŠ å¯†å­˜å‚¨APIå¯†é’¥
        self._encrypted_api_keys = self._cipher.encrypt(
            json.dumps(keys).encode()
        )

# âœ… Contextè®¿é—®æ§åˆ¶
class ContextAccessControl:
    def __init__(self):
        self.permissions = {}
    
    def grant_permission(self, component: str, fields: list[str]):
        self.permissions[component] = fields
    
    def check_access(self, component: str, field: str) -> bool:
        allowed_fields = self.permissions.get(component, [])
        return field in allowed_fields or field in ["user_id"]  # user_idæ€»æ˜¯å…è®¸
    
    def filter_context(self, context: Context, component: str) -> dict:
        filtered = {}
        for field in fields(context):
            if self.check_access(component, field.name):
                filtered[field.name] = getattr(context, field.name)
        return filtered
```

### Q4: Contextç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜

**é—®é¢˜**: Contextç»“æ„å˜æ›´å¯¼è‡´æ—§ç‰ˆæœ¬ä¸å…¼å®¹ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… Contextç‰ˆæœ¬ç®¡ç†
@dataclass
class VersionedContext:
    version: str = "1.0"
    user_id: str = ""
    model: str = "gpt-4"
    
    @classmethod
    def from_dict(cls, data: dict) -> 'VersionedContext':
        version = data.get("version", "1.0")
        
        if version == "1.0":
            return cls(**data)
        elif version == "2.0":
            # å¤„ç†ç‰ˆæœ¬2.0çš„å·®å¼‚
            return cls.migrate_from_v2(data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„Contextç‰ˆæœ¬: {version}")
    
    @classmethod
    def migrate_from_v2(cls, data: dict) -> 'VersionedContext':
        # ä»v2.0è¿ç§»åˆ°å½“å‰ç‰ˆæœ¬
        migrated_data = {
            "version": "1.0",
            "user_id": data.get("userId", ""),  # å­—æ®µåå˜æ›´
            "model": data.get("llm_model", "gpt-4")  # å­—æ®µåå˜æ›´
        }
        return cls(**migrated_data)

# âœ… Contextæ¨¡å¼éªŒè¯
from pydantic import BaseModel, validator

class ValidatedContext(BaseModel):
    user_id: str
    model: str
    language: str = "zh-CN"
    
    @validator('user_id')
    def validate_user_id(cls, v):
        if not v or len(v) < 3:
            raise ValueError('user_idå¿…é¡»è‡³å°‘3ä¸ªå­—ç¬¦')
        return v
    
    @validator('model')
    def validate_model(cls, v):
        allowed_models = ['gpt-4', 'claude-3', 'azure_openai/gpt-4o']
        if v not in allowed_models:
            raise ValueError(f'ä¸æ”¯æŒçš„æ¨¡å‹: {v}')
        return v
```

## æ€»ç»“

LangGraphçš„Contextç³»ç»Ÿä¸ºAIæ™ºèƒ½ä½“æä¾›äº†å¼ºå¤§è€Œçµæ´»çš„ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ã€‚é€šè¿‡ç†è§£**é™æ€è¿è¡Œæ—¶Context**ã€**åŠ¨æ€è¿è¡Œæ—¶Contextï¼ˆçŠ¶æ€ï¼‰**å’Œ**åŠ¨æ€è·¨ä¼šè¯Contextï¼ˆå­˜å‚¨ï¼‰**ä¸‰ç§ç±»å‹ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºå‡ºå…·æœ‰ä¸°å¯Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„æ™ºèƒ½åº”ç”¨ã€‚

### å…³é”®è¦ç‚¹å›é¡¾

1. **Contextå·¥ç¨‹æ ¸å¿ƒ**: åœ¨æ­£ç¡®çš„æ—¶é—´ï¼Œä»¥æ­£ç¡®çš„æ ¼å¼ï¼Œæä¾›æ­£ç¡®çš„ä¿¡æ¯
2. **ä¸‰ç§Contextç±»å‹**: é™æ€è¿è¡Œæ—¶ã€åŠ¨æ€è¿è¡Œæ—¶ï¼ˆçŠ¶æ€ï¼‰ã€åŠ¨æ€è·¨ä¼šè¯ï¼ˆå­˜å‚¨ï¼‰
3. **è®¾è®¡åŸåˆ™**: ç»“æ„åŒ–ã€å®‰å…¨æ€§ã€æ€§èƒ½ä¼˜åŒ–ã€ç‰ˆæœ¬å…¼å®¹æ€§
4. **å®è·µç»éªŒ**: ä»æœ¬é¡¹ç›®çš„å®ç°ä¸­å­¦ä¹ æœ€ä½³å®è·µå’Œå¸¸è§é™·é˜±

### Contextç³»ç»Ÿçš„ä»·å€¼

- ğŸ¯ **ä¸ªæ€§åŒ–**: æ ¹æ®ç”¨æˆ·Contextæä¾›å®šåˆ¶åŒ–æœåŠ¡
- ğŸ”§ **å·¥å…·é›†æˆ**: é€šè¿‡Contextè®¿é—®å„ç§å¤–éƒ¨èµ„æº
- ğŸ’¾ **çŠ¶æ€ç®¡ç†**: åœ¨å¯¹è¯è¿‡ç¨‹ä¸­ä¿æŒå’Œæ¼”åŒ–çŠ¶æ€
- ğŸŒ **è·¨ä¼šè¯è®°å¿†**: åœ¨ä¸åŒä¼šè¯é—´å…±äº«å’Œå­¦ä¹ ä¿¡æ¯

æŒæ¡Contextç³»ç»Ÿï¼Œå°†å¸®åŠ©æ‚¨æ„å»ºæ›´æ™ºèƒ½ã€æ›´æœ‰ç”¨çš„AIåº”ç”¨ï¼

---

**å‚è€ƒèµ„æ–™**:
- [LangGraph Context å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/agents/context/)
- [LangGraph Memory æ¦‚å¿µ](https://langchain-ai.github.io/langgraph/concepts/memory/)
- æœ¬é¡¹ç›®æºç  - Contextç³»ç»Ÿçš„å®é™…å®ç°ç¤ºä¾‹
